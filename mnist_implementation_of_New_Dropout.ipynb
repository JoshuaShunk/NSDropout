{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist implementation of New_Dropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "4a10260d53feadc3aac998a3ba3a60b43aac84189bada71a196791e24306642d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('AITraining': virtualenvwrapper)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshuaShunk/NSDropout/blob/main/mnist_implementation_of_New_Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2GytIidUnpd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aLxFoLMU2jC"
      },
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvOLv3jSjsxV"
      },
      "source": [
        "np.random.seed(seed=21)"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX886WxClQ07",
        "outputId": "aa0eb078-76db-4482-da57-718da8311716"
      },
      "source": [
        "print(np.random.random(size=3))"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.04872488 0.28910966 0.72096635]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NkY3EiBU4tR",
        "cellView": "form"
      },
      "source": [
        "#@title Load Layers\n",
        "\n",
        "# Dense layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons,\n",
        "                 weight_regularizer_l1=0, weight_regularizer_l2=0,\n",
        "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "        # Set regularization strength\n",
        "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
        "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
        "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
        "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "\n",
        "        # Gradients on regularization\n",
        "        # L1 on weights\n",
        "        if self.weight_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.weights)\n",
        "            dL1[self.weights < 0] = -1\n",
        "            self.dweights += self.weight_regularizer_l1 * dL1\n",
        "        # L2 on weights\n",
        "        if self.weight_regularizer_l2 > 0:\n",
        "            self.dweights += 2 * self.weight_regularizer_l2 * \\\n",
        "                             self.weights\n",
        "        # L1 on biases\n",
        "        if self.bias_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.biases)\n",
        "            dL1[self.biases < 0] = -1\n",
        "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
        "        # L2 on biases\n",
        "        if self.bias_regularizer_l2 > 0:\n",
        "            self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
        "                            self.biases\n",
        "\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "# ReLU activation\n",
        "\n",
        "\n",
        "class Activation_ReLU:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Since we need to modify original variable,\n",
        "        # let's make a copy of values first\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "\n",
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
        "                                            keepdims=True))\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
        "                                            keepdims=True)\n",
        "\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in \\\n",
        "                enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - \\\n",
        "                              np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient\n",
        "            # and add it to the array of sample gradients\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
        "                                         single_dvalues)\n",
        "    def predictions(self, outputs):\n",
        "        return np.argmax(outputs, axis=1)\n",
        "\n",
        "\n",
        "# Sigmoid activation\n",
        "class Activation_Sigmoid:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Save input and calculate/save output\n",
        "        # of the sigmoid function\n",
        "        self.inputs = inputs\n",
        "        self.output = 1 / (1 + np.exp(-inputs))\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Derivative - calculates from output of the sigmoid function\n",
        "        self.dinputs = dvalues * (1 - self.output) * self.output\n",
        "\n",
        "\n",
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.momentum = momentum\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If we use momentum\n",
        "        if self.momentum:\n",
        "\n",
        "            # If layer does not contain momentum arrays, create them\n",
        "            # filled with zeros\n",
        "            if not hasattr(layer, 'weight_momentums'):\n",
        "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "                # If there is no momentum array for weights\n",
        "                # The array doesn't exist for biases yet either.\n",
        "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "\n",
        "            # Build weight updates with momentum - take previous\n",
        "            # updates multiplied by retain factor and update with\n",
        "            # current gradients\n",
        "            weight_updates = \\\n",
        "                self.momentum * layer.weight_momentums - \\\n",
        "                self.current_learning_rate * layer.dweights\n",
        "            layer.weight_momentums = weight_updates\n",
        "\n",
        "            # Build bias updates\n",
        "            bias_updates = \\\n",
        "                self.momentum * layer.bias_momentums - \\\n",
        "                self.current_learning_rate * layer.dbiases\n",
        "            layer.bias_momentums = bias_updates\n",
        "\n",
        "        # Vanilla SGD updates (as before momentum update)\n",
        "        else:\n",
        "            weight_updates = -self.current_learning_rate * \\\n",
        "                             layer.dweights\n",
        "            bias_updates = -self.current_learning_rate * \\\n",
        "                           layer.dbiases\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.biases += bias_updates\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adagrad optimizer\n",
        "class Optimizer_Adagrad:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache += layer.dweights ** 2\n",
        "        layer.bias_cache += layer.dbiases ** 2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# RMSprop optimizer\n",
        "class Optimizer_RMSprop:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 rho=0.9):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.rho = rho\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.rho * layer.weight_cache + \\\n",
        "                             (1 - self.rho) * layer.dweights ** 2\n",
        "        layer.bias_cache = self.rho * layer.bias_cache + \\\n",
        "                           (1 - self.rho) * layer.dbiases ** 2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adam optimizer\n",
        "class Optimizer_Adam:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.02, decay=0., epsilon=1e-7,\n",
        "                 beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update momentum  with current gradients\n",
        "        layer.weight_momentums = self.beta_1 * \\\n",
        "                                 layer.weight_momentums + \\\n",
        "                                 (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * \\\n",
        "                               layer.bias_momentums + \\\n",
        "                               (1 - self.beta_1) * layer.dbiases\n",
        "        # Get corrected momentum\n",
        "        # self.iteration is 0 at first pass\n",
        "        # and we need to start with 1 here\n",
        "        weight_momentums_corrected = layer.weight_momentums / \\\n",
        "                                     (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / \\\n",
        "                                   (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
        "                             (1 - self.beta_2) * layer.dweights ** 2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
        "                           (1 - self.beta_2) * layer.dbiases ** 2\n",
        "        # Get corrected cache\n",
        "        weight_cache_corrected = layer.weight_cache / \\\n",
        "                                 (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / \\\n",
        "                               (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         weight_momentums_corrected / \\\n",
        "                         (np.sqrt(weight_cache_corrected) +\n",
        "                          self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        bias_momentums_corrected / \\\n",
        "                        (np.sqrt(bias_cache_corrected) +\n",
        "                         self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Common loss class\n",
        "class Loss:\n",
        "\n",
        "\n",
        "    # Regularization loss calculation\n",
        "    def regularization_loss(self, layer):\n",
        "\n",
        "        # 0 by default\n",
        "        regularization_loss = 0\n",
        "\n",
        "        # L1 regularization - weights\n",
        "        # calculate only when factor greater than 0\n",
        "        if layer.weight_regularizer_l1 > 0:\n",
        "            regularization_loss += layer.weight_regularizer_l1 * \\\n",
        "                                   np.sum(np.abs(layer.weights))\n",
        "\n",
        "        # L2 regularization - weights\n",
        "        if layer.weight_regularizer_l2 > 0:\n",
        "            regularization_loss += layer.weight_regularizer_l2 * \\\n",
        "                                   np.sum(layer.weights *\n",
        "                                          layer.weights)\n",
        "\n",
        "        # L1 regularization - biases\n",
        "        # calculate only when factor greater than 0\n",
        "        if layer.bias_regularizer_l1 > 0:\n",
        "            regularization_loss += layer.bias_regularizer_l1 * \\\n",
        "                                   np.sum(np.abs(layer.biases))\n",
        "\n",
        "        # L2 regularization - biases\n",
        "        if layer.bias_regularizer_l2 > 0:\n",
        "            regularization_loss += layer.bias_regularizer_l2 * \\\n",
        "                                   np.sum(layer.biases *\n",
        "                                          layer.biases)\n",
        "\n",
        "        return regularization_loss\n",
        "\n",
        "\n",
        "    # Set/remember trainable layers\n",
        "    def remember_trainable_layers(self, trainable_layers):\n",
        "        self.trainable_layers = trainable_layers\n",
        "\n",
        "    # Calculates the data and regularization losses\n",
        "    # given model output and ground truth values\n",
        "    def calculate(self, output, y, *, include_regularization=False):\n",
        "\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = np.mean(sample_losses)\n",
        "\n",
        "        # Return loss\n",
        "        return data_loss\n",
        "\n",
        "    # Calculates accumulated loss\n",
        "    def calculate_accumulated(self, *, include_regularization=False):\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = self.accumulated_sum / self.accumulated_count\n",
        "\n",
        "        # If just data loss - return it\n",
        "        if not include_regularization:\n",
        "            return data_loss\n",
        "\n",
        "        # Return the data and regularization losses\n",
        "        return data_loss, self.regularization_loss()\n",
        "\n",
        "    # Reset variables for accumulated loss\n",
        "    def new_pass(self):\n",
        "        self.accumulated_sum = 0\n",
        "        self.accumulated_count = 0\n",
        "\n",
        "\n",
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "\n",
        "        # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Number of samples in a batch\n",
        "        samples = len(y_pred)\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[\n",
        "                range(samples),\n",
        "                y_true\n",
        "            ]\n",
        "\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(\n",
        "                y_pred_clipped * y_true,\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of labels in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        # If labels are sparse, turn them into one-hot vector\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Softmax classifier - combined Softmax activation\n",
        "# and cross-entropy loss for faster backward step\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "\n",
        "    # Creates activation and loss function objects\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, y_true):\n",
        "        # Output layer's activation function\n",
        "        self.activation.forward(inputs)\n",
        "        # Set the output\n",
        "        self.output = self.activation.output\n",
        "        # Calculate and return loss value\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "\n",
        "        # If labels are one-hot encoded,\n",
        "        # turn them into discrete values\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "        # Copy so we can safely modify\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Calculate gradient\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Binary cross-entropy loss\n",
        "class Loss_BinaryCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Calculate sample-wise loss\n",
        "        sample_losses = -(y_true * np.log(y_pred_clipped) +\n",
        "                          (1 - y_true) * np.log(1 - y_pred_clipped))\n",
        "        sample_losses = np.mean(sample_losses, axis=-1)\n",
        "\n",
        "        # Return losses\n",
        "        return sample_losses\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of outputs in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        outputs = len(dvalues[0])\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -(y_true / clipped_dvalues -\n",
        "                         (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "# Common accuracy class\n",
        "class Accuracy:\n",
        "\n",
        "    # Calculates an accuracy\n",
        "    # given predictions and ground truth values\n",
        "    def calculate(self, predictions, y):\n",
        "\n",
        "        # Get comparison results\n",
        "        comparisons = self.compare(predictions, y)\n",
        "\n",
        "        # Calculate an accuracy\n",
        "        accuracy = np.mean(comparisons)\n",
        "\n",
        "        # Add accumulated sum of matching values and sample count\n",
        "        # Return accuracy\n",
        "        return accuracy\n",
        "\n",
        "    # Calculates accumulated accuracy\n",
        "    def calculate_accumulated(self):\n",
        "\n",
        "        # Calculate an accuracy\n",
        "        accuracy = self.accumulated_sum / self.accumulated_count\n",
        "\n",
        "        # Return the data and regularization losses\n",
        "        return accuracy\n",
        "\n",
        "    # Reset variables for accumulated accuracy\n",
        "    def new_pass(self):\n",
        "        self.accumulated_sum = 0\n",
        "        self.accumulated_count = 0\n",
        "\n",
        "\n",
        "# Accuracy calculation for classification model\n",
        "class Accuracy_Categorical(Accuracy):\n",
        "\n",
        "    def __init__(self, *, binary=False):\n",
        "        # Binary mode?\n",
        "        self.binary = binary\n",
        "\n",
        "    # No initialization is needed\n",
        "    def init(self, y):\n",
        "        pass\n",
        "\n",
        "    # Compares predictions to the ground truth values\n",
        "    def compare(self, predictions, y):\n",
        "        if not self.binary and len(y.shape) == 2:\n",
        "            y = np.argmax(y, axis=1)\n",
        "        return predictions == y\n",
        "\n",
        "\n",
        "# Accuracy calculation for regression model\n",
        "class Accuracy_Regression(Accuracy):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Create precision property\n",
        "        self.precision = None\n",
        "\n",
        "    # Calculates precision value\n",
        "    # based on passed-in ground truth values\n",
        "    def init(self, y, reinit=False):\n",
        "        if self.precision is None or reinit:\n",
        "            self.precision = np.std(y) / 250\n",
        "\n",
        "    # Compares predictions to the ground truth values\n",
        "    def compare(self, predictions, y):\n",
        "        return np.absolute(predictions - y) < self.precision\n",
        "\n",
        "class model:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self, classes, samples):\n",
        "        self.classes = classes\n",
        "        self.samples = samples\n",
        "        self.X, self.y = spiral_data(samples=self.samples, classes=self.classes)\n",
        "        dense1.forward(self.X)\n",
        "        activation1.forward(dense1.output)\n",
        "        dense2.forward(activation1.output)\n",
        "        activation2.forward(dense2.output)\n",
        "        # Calculate the data loss\n",
        "        self.loss = loss_function.calculate(activation2.output, self.y)\n",
        "        self.predictions = (activation2.output > 0.5) * 1\n",
        "        self.accuracy = np.mean(self.predictions == self.y)\n",
        "        print(f'Accuracy: {self.accuracy}')\n",
        "\n",
        "\n"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA4GFMbIPUkI"
      },
      "source": [
        "# Old Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxoiO43tPbTa"
      },
      "source": [
        "class Layer_Dropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        # Store rate, we invert it as for example for dropout\n",
        "        # of 0.1 we need success rate of 0.9\n",
        "        self.rate = 1 - rate\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Save input values\n",
        "        self.inputs = inputs\n",
        "        # Generate and save scaled mask\n",
        "        self.binary_mask = np.random.binomial(1, self.rate,\n",
        "                                              size=inputs.shape) / self.rate\n",
        "        # Apply mask to output values\n",
        "        self.output = inputs * self.binary_mask\n",
        "       \n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "        #print(self.dinputs.shape)"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_Og9ZrbKtV"
      },
      "source": [
        "# New Dropout Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXBWsHDIUSfh"
      },
      "source": [
        "class Layer_BinaryNSDropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        self.rate = 1 - rate\n",
        "        self.iterations = 0\n",
        "\n",
        "    def forward(self, inputs, val_inputs):\n",
        "        self.inputs = inputs\n",
        "        self.val_inputs = val_inputs\n",
        "        nummask = round(len(self.inputs[0]) * self.rate)\n",
        "        \n",
        "        #Averaging Values\n",
        "        self.meanarray1 = np.mean(inputs, axis=0)\n",
        "        self.meanarray2 = np.mean(val_inputs, axis=0)\n",
        "\n",
        "        if self.iterations != 0:\n",
        "            # Calculating value\n",
        "            self.difference = self.meanarray1 - self.meanarray2\n",
        "            ind = np.argpartition(self.difference, -nummask)[-nummask:]\n",
        "            mask = np.ones(self.meanarray1.shape, dtype=bool)\n",
        "            mask[ind] = False\n",
        "            self.difference[~mask] = 1\n",
        "            self.difference[mask] = 0. \n",
        "            self.binary_mask = self.difference / self.rate\n",
        "\n",
        "        else:\n",
        "            self.binary_mask = np.random.binomial(1, self.rate,\n",
        "                                                  size=inputs.shape) / self.rate\n",
        "        self.output = inputs * self.binary_mask\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1"
      ],
      "execution_count": 329,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiuCzwWxbRl0"
      },
      "source": [
        "class Layer_CatagoricalNSDropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        self.rate = rate\n",
        "        self.iterations = 0\n",
        "\n",
        "    def forward(self, X_test, y_test, X, y):        \n",
        "        if self.iterations != 0:\n",
        "          #Sorting data into classes\n",
        "          idx = np.argsort(y_test)\n",
        "          X_test_sorted = X_test[idx]\n",
        "          y_test_sorted = y_test[idx]\n",
        "\n",
        "          idx2 = np.argsort(y)\n",
        "          X_train_sorted = X[idx2]\n",
        "          y_train_sorted = y[idx2]\n",
        "\n",
        "          #Adding sorted data into dictionaries \n",
        "          sorted_x = {}\n",
        "          sorted_y = {}\n",
        "          for classes in range(len(set(y))):\n",
        "            sorted_x[\"class_{0}\".format(classes)] = X[y == classes]\n",
        "            sorted_y[\"label_{0}\".format(classes)] = y[y == classes]\n",
        "\n",
        "          sorted_x_test = {}\n",
        "          sorted_y_test = {}\n",
        "          for classes in range(len(set(y))):\n",
        "            sorted_x_test[\"class_{0}\".format(classes)] = X_test[y_test == classes]\n",
        "            sorted_y_test[\"label_{0}\".format(classes)] = y_test[y_test == classes]\n",
        "\n",
        "          #Averaging sorted data from each class then finding the difference between the averaged train and test inputs\n",
        "          differnce_classes = {}\n",
        "          for i, classes, test_classes in zip(range(len(set(y))), sorted_x, sorted_x_test):\n",
        "            differnce_classes[\"diff_{0}\".format(i)] = np.mean(sorted_x[classes], axis=0) - np.mean(sorted_x_test[classes], axis=0)\n",
        "\n",
        "          #Masking the data taking the high values(greatest difference between train and test) and setting their values to 0\n",
        "          self.diff_mask = {}\n",
        "          for i, classes, test_classes, diff in zip(range(len(set(y))), sorted_x, sorted_x_test, differnce_classes):\n",
        "            ind = np.argpartition(differnce_classes[diff], -round(len(X[0]) * self.rate))[-round(len(X[0]) * self.rate):]\n",
        "            mask = np.ones(np.mean(sorted_x[classes],axis=0).shape, dtype=bool)\n",
        "            mask[ind] = False\n",
        "            differnce_classes[diff][~mask] = 0.\n",
        "            differnce_classes[diff][mask] = 1\n",
        "            self.diff_mask[\"mask_{0}\".format(i)] = differnce_classes[diff]\n",
        "\n",
        "          #Goes through each input values and applies the apprioprite mask based on what the true output should be.\n",
        "          binary_mask = np.empty(shape=X.shape)\n",
        "          for i, input, label in zip(range(len(X)), X, y):\n",
        "            for true, diff in zip(range(len(set(y))),self.diff_mask):\n",
        "              if label == true:\n",
        "                self.binary_mask[i] = self.diff_mask[diff]\n",
        "        else:\n",
        "          self.binary_mask = np.random.binomial(1, (1-self.rate), size=X.shape)\n",
        "        \n",
        "        self.output = (self.binary_mask/(1-self.rate)) * X\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "\n",
        "    def infrence(self, input, label):\n",
        "        self.input = input\n",
        "        self.label = label\n",
        "        idx = np.argsort(self.label)\n",
        "        input_sorted = input[idx]\n",
        "        label_sorted = label[idx]\n",
        "\n",
        "        self.ingrence_binary_mask = np.empty(shape=self.input.shape)\n",
        "        for i, input, label in zip(range(len(self.input)), self.input, self.label):\n",
        "          for true, diff in zip(range(len(set(self.label))),self.diff_mask):\n",
        "            if label == true:\n",
        "              self.ingrence_binary_mask[i] = self.diff_mask[diff]\n",
        "\n",
        "        self.output = self.ingrence_binary_mask * self.input\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRB57nFublm3"
      },
      "source": [
        "Initializing Caches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kyAX0txV-cF"
      },
      "source": [
        "loss_cache = []\n",
        "val_loss_cache = []\n",
        "acc_cache = []\n",
        "val_acc_cache = []\n",
        "lr_cache = []\n",
        "epoch_cache = []\n",
        "test_acc_cache = []\n",
        "test_loss_cache = []\n",
        "\n",
        "max_val_accuracyint = 0"
      ],
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_7VWnIlF8yx"
      },
      "source": [
        "Initializing Summary List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtnu5VToGAq0"
      },
      "source": [
        "summary = []"
      ],
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Eu0pm-WjKI"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-24YuBKre0f"
      },
      "source": [
        "Vizulizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kUOJ9avrho8",
        "outputId": "40df6779-aa49-4a4b-8dab-2ced9cc8e339"
      },
      "source": [
        "(X, y), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Label index to label name relation\n",
        "fashion_mnist_labels = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}\n",
        "\n",
        "\n",
        "# Shuffle the training dataset\n",
        "keys = np.array(range(X.shape[0]))\n",
        "np.random.shuffle(keys)\n",
        "X = X[keys]\n",
        "y = y[keys]\n",
        "\n",
        "X = X[:1000,:,:]\n",
        "X_test = X_test[:200,:,:]\n",
        "y = y[:1000]\n",
        "y_test  = y_test[:200]\n",
        "\n",
        "# Scale and reshape samples\n",
        "X = (X.reshape(X.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
        "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) -\n",
        "             127.5) / 127.5\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 784)\n",
            "(1000,)\n",
            "(200, 784)\n",
            "(200,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_nW7mqGTnem"
      },
      "source": [
        "Sorting Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtvA9y81TpGf",
        "outputId": "afcf7412-2bcf-49a8-88e6-7d46a31fa108"
      },
      "source": [
        "idx = np.argsort(y)\n",
        "X_sorted = X[idx]\n",
        "y_sorted = y[idx]\n",
        "\n",
        "sorted_x = {}\n",
        "sorted_y = {}\n",
        "for classes in fashion_mnist_labels:\n",
        "  sorted_x[\"X_{0}\".format(classes)] = X[y == classes]\n",
        "  sorted_y[\"y_{0}\".format(classes)] = y[y == classes]\n",
        "\n",
        "\n",
        "\n",
        "for sorted_lists in sorted_x:\n",
        "  print(f'Number of Samples for {sorted_lists}: {sorted_x[sorted_lists].shape[0]}')\n"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples for X_0: 126\n",
            "Number of Samples for X_1: 101\n",
            "Number of Samples for X_2: 104\n",
            "Number of Samples for X_3: 103\n",
            "Number of Samples for X_4: 92\n",
            "Number of Samples for X_5: 99\n",
            "Number of Samples for X_6: 95\n",
            "Number of Samples for X_7: 91\n",
            "Number of Samples for X_8: 97\n",
            "Number of Samples for X_9: 92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpaNaUO3kP2G"
      },
      "source": [
        "Sorting Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBLFeGAUkSOs",
        "outputId": "5123e943-9d33-45af-a1b7-6d3fd9359785"
      },
      "source": [
        "idx = np.argsort(y_test)\n",
        "X_test_sorted = X_test[idx]\n",
        "y_test_sorted = y_test[idx]\n",
        "\n",
        "class_list = []\n",
        "\n",
        "sorted_x_test = {}\n",
        "sorted_y_test = {}\n",
        "for classes in fashion_mnist_labels:\n",
        "  sorted_x_test[\"X_test_{0}\".format(classes)] = X_test[y_test == classes]\n",
        "  sorted_y_test[\"y_test_{0}\".format(classes)] = y_test[y_test == classes]\n",
        "\n",
        "\n",
        "for sorted_lists in sorted_x_test:\n",
        "  print(f'Number of Samples for {sorted_lists}: {sorted_x_test[sorted_lists].shape[0]}')\n",
        "  class_list.append(sorted_x_test[sorted_lists].shape[0])\n"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples for X_test_0: 20\n",
            "Number of Samples for X_test_1: 27\n",
            "Number of Samples for X_test_2: 27\n",
            "Number of Samples for X_test_3: 17\n",
            "Number of Samples for X_test_4: 21\n",
            "Number of Samples for X_test_5: 16\n",
            "Number of Samples for X_test_6: 16\n",
            "Number of Samples for X_test_7: 20\n",
            "Number of Samples for X_test_8: 18\n",
            "Number of Samples for X_test_9: 18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd_dSHDNW1Rn"
      },
      "source": [
        "# Initializing Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aly5fwUCW_4l"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Create Dense layer with 2 input features and 64 output values\n",
        "dense1 = Layer_Dense(X.shape[1], 128, weight_regularizer_l2=5e-4,\n",
        "                     bias_regularizer_l2=5e-4)\n",
        "\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "dropout1 = Layer_CatagoricalNSDropout(0.2)\n",
        "\n",
        "dense2 = Layer_Dense(128, 128)\n",
        "\n",
        "activation2 = Activation_ReLU()\n",
        "\n",
        "dense3 = Layer_Dense(128,128)\n",
        "\n",
        "activation3 = Activation_ReLU()\n",
        "\n",
        "dense4 = Layer_Dense(128,len(set(y)))\n",
        "\n",
        "activation4 = Activation_Softmax()\n",
        "\n",
        "\n",
        "loss_function = Loss_CategoricalCrossentropy()\n",
        "\n",
        "softmax_classifier_output = \\\n",
        "                Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = Optimizer_Adam(decay=5e-7,learning_rate=0.01)\n",
        "#optimizer = Optimizer_SGD(learning_rate=0.01)\n",
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(y)\n",
        "\n"
      ],
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hbnq4TJp1cl",
        "outputId": "f75d444e-f7e0-4831-da44-2441fda67bcb"
      },
      "source": [
        "print(f'Found {X.shape[0]} images belonging to {len(set(y))} unique classes')"
      ],
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1000 images belonging to 10 unique classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xmbxDuwXIBk"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14yHOjq9XLee",
        "outputId": "64204552-eeb0-4860-a19b-baf0330e8720"
      },
      "source": [
        "epochs = 500\n",
        "dips = 0\n",
        "accuracy_count = 0\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "    dense1.forward(X)\n",
        "\n",
        "    activation1.forward(dense1.output)\n",
        "\n",
        "    if epoch != 0:\n",
        "      cached_val_inputs = cached_val_inputs\n",
        "      cached_train_inputs = activation1.output\n",
        "    else:\n",
        "      cached_val_inputs = np.random.random(size=128) #Never used just needed to pass to dropout\n",
        "      cached_train_inputs = activation1.output\n",
        "\n",
        "    #print(activation1.output.shape)\n",
        "\n",
        "    #dropout1.forward(inputs=activation1.output, val_inputs=cached_val_inputs)\n",
        "    dropout1.forward(X=activation1.output, y=y, X_test=cached_val_inputs, y_test=y_test)\n",
        "    #print(dropout1.output.shape)\n",
        "\n",
        "    dense2.forward(dropout1.output)\n",
        "\n",
        "    activation2.forward(dense2.output)\n",
        "\n",
        "    dense3.forward(activation2.output)\n",
        "\n",
        "    activation3.forward(dense3.output)\n",
        "\n",
        "    dense4.forward(activation3.output)\n",
        "\n",
        "    activation4.forward(dense4.output)\n",
        "\n",
        "    # Calculate the data loss\n",
        "    data_loss = loss_function.calculate(activation4.output, y)\n",
        "    regularization_loss = \\\n",
        "      loss_function.regularization_loss(dense1) + \\\n",
        "      loss_function.regularization_loss(dense2) + \\\n",
        "      loss_function.regularization_loss(dense3) + \\\n",
        "      loss_function.regularization_loss(dense4) \n",
        "    loss = data_loss + regularization_loss\n",
        "    \n",
        "    #Accuracy\n",
        "    predictions = activation4.predictions(activation4.output)\n",
        "    train_accuracy = accuracy.calculate(predictions, y)\n",
        "\n",
        "    # Backward pass\n",
        "    softmax_classifier_output.backward(activation4.output, y)\n",
        "    activation4.backward(softmax_classifier_output.dinputs)\n",
        "    dense4.backward(activation4.dinputs)\n",
        "    activation3.backward(dense4.dinputs)\n",
        "    dense3.backward(activation3.dinputs)\n",
        "    activation2.backward(dense3.dinputs)\n",
        "    dense2.backward(activation2.dinputs)\n",
        "    dropout1.backward(dense2.dinputs)\n",
        "    activation1.backward(dropout1.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "    \n",
        "    # Update weights and biases\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.update_params(dense2)\n",
        "    optimizer.update_params(dense3)\n",
        "    optimizer.update_params(dense4)\n",
        "    optimizer.post_update_params()\n",
        "    dropout1.post_update_params()\n",
        "\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    dense1.forward(X_test)\n",
        "    activation1.forward(dense1.output)\n",
        "    \n",
        "    if epoch == 0:\n",
        "      dense2.forward(activation1.output)\n",
        "    else:\n",
        "      dropout1.infrence(activation1.output,y_test)\n",
        "\n",
        "      dense2.forward(dropout1.output)\n",
        "    \n",
        "    dense1_outputs = dense1.output\n",
        "    meanarray = np.mean(dense1.output, axis=0)\n",
        "    cached_val_inputs = activation1.output\n",
        " \n",
        "    trainout = meanarray\n",
        "    activation2.forward(dense2.output)\n",
        "\n",
        "    dense3.forward(activation2.output)\n",
        "    activation3.forward(dense3.output)\n",
        "    dense4.forward(activation3.output)\n",
        "    activation4.forward(dense4.output)\n",
        "    # Calculate the data loss\n",
        "    valloss = loss_function.calculate(activation4.output, y_test)\n",
        "    predictions = activation4.predictions(activation4.output)\n",
        "    valaccuracy = accuracy.calculate(predictions, y_test)\n",
        "\n",
        "    #Updating List\n",
        "    loss_cache.append(loss)\n",
        "    val_loss_cache.append(valloss)\n",
        "    acc_cache.append(train_accuracy)\n",
        "    val_acc_cache.append(valaccuracy)\n",
        "    lr_cache.append(optimizer.current_learning_rate)\n",
        "    epoch_cache.append(epoch)\n",
        " \n",
        "\n",
        "    if valaccuracy >= .992:\n",
        "      break\n",
        "\n",
        "    #Summary Items\n",
        "    if valaccuracy >= .8 and len(summary) == 0:\n",
        "        nintypercent = f'Model hit 80% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .85 and len(summary) == 1:\n",
        "        nintypercent = f'Model hit 85% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .9 and len(summary) == 2:\n",
        "        nintypercent = f'Model hit 90% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .95 and len(summary) == 3:\n",
        "        nintypercent = f'Model hit 95% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .975 and len(summary) == 4:\n",
        "        nintypercent = f'Model hit 97.5% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)  \n",
        "    if valaccuracy >= 1 and len(summary) == 5:\n",
        "        nintypercent = f'Model hit 100% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if epoch == epochs:\n",
        "      if valaccuracy > max_val_accuracyint:\n",
        "        max_val_accuracyint = valaccuracy\n",
        "        max_val_accuracy = f'Max accuracy was {valaccuracy * 100}% at epoch {epoch}.'\n",
        "        summary.append(max_val_accuracy)\n",
        "      else:\n",
        "        summary.append(max_val_accuracy)\n",
        "    else:\n",
        "      if valaccuracy > max_val_accuracyint:\n",
        "        max_val_accuracyint = valaccuracy\n",
        "        max_val_accuracy = f'Max accuracy was {valaccuracy * 100}% at epoch {epoch}.'     \n",
        "    \n",
        "    if not epoch % 1:\n",
        "        print(f'epoch: {epoch}, ' +\n",
        "              f'acc: {train_accuracy:.3f}, ' +\n",
        "              f'loss: {loss:.3f} (' +\n",
        "              f'data_loss: {data_loss:.3f}, ' +\n",
        "              f'reg_loss: {regularization_loss:.3f}), ' +\n",
        "              f'lr: {optimizer.current_learning_rate:.9f} ' +\n",
        "              f'validation, acc: {valaccuracy:.3f}, loss: {valloss:.3f} ')"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.049, loss: 2.308 (data_loss: 2.303, reg_loss: 0.005), lr: 0.010000000 validation, acc: 0.100, loss: 2.301 \n",
            "epoch: 1, acc: 0.126, loss: 2.303 (data_loss: 2.301, reg_loss: 0.002), lr: 0.009999995 validation, acc: 0.100, loss: 2.270 \n",
            "epoch: 2, acc: 0.126, loss: 2.267 (data_loss: 2.266, reg_loss: 0.001), lr: 0.009999990 validation, acc: 0.180, loss: 2.016 \n",
            "epoch: 3, acc: 0.225, loss: 1.994 (data_loss: 1.991, reg_loss: 0.003), lr: 0.009999985 validation, acc: 0.310, loss: 1.758 \n",
            "epoch: 4, acc: 0.313, loss: 1.772 (data_loss: 1.766, reg_loss: 0.006), lr: 0.009999980 validation, acc: 0.230, loss: 2.058 \n",
            "epoch: 5, acc: 0.196, loss: 2.081 (data_loss: 2.073, reg_loss: 0.008), lr: 0.009999975 validation, acc: 0.485, loss: 1.578 \n",
            "epoch: 6, acc: 0.395, loss: 1.619 (data_loss: 1.610, reg_loss: 0.009), lr: 0.009999970 validation, acc: 0.420, loss: 1.542 \n",
            "epoch: 7, acc: 0.327, loss: 1.644 (data_loss: 1.633, reg_loss: 0.011), lr: 0.009999965 validation, acc: 0.450, loss: 1.535 \n",
            "epoch: 8, acc: 0.351, loss: 1.654 (data_loss: 1.641, reg_loss: 0.013), lr: 0.009999960 validation, acc: 0.500, loss: 1.394 \n",
            "epoch: 9, acc: 0.433, loss: 1.473 (data_loss: 1.457, reg_loss: 0.016), lr: 0.009999955 validation, acc: 0.645, loss: 1.270 \n",
            "epoch: 10, acc: 0.556, loss: 1.368 (data_loss: 1.350, reg_loss: 0.018), lr: 0.009999950 validation, acc: 0.650, loss: 1.219 \n",
            "epoch: 11, acc: 0.617, loss: 1.297 (data_loss: 1.277, reg_loss: 0.020), lr: 0.009999945 validation, acc: 0.615, loss: 1.085 \n",
            "epoch: 12, acc: 0.582, loss: 1.210 (data_loss: 1.187, reg_loss: 0.022), lr: 0.009999940 validation, acc: 0.615, loss: 0.949 \n",
            "epoch: 13, acc: 0.564, loss: 1.105 (data_loss: 1.081, reg_loss: 0.024), lr: 0.009999935 validation, acc: 0.705, loss: 0.906 \n",
            "epoch: 14, acc: 0.679, loss: 1.025 (data_loss: 1.000, reg_loss: 0.025), lr: 0.009999930 validation, acc: 0.725, loss: 0.873 \n",
            "epoch: 15, acc: 0.689, loss: 1.690 (data_loss: 1.663, reg_loss: 0.027), lr: 0.009999925 validation, acc: 0.745, loss: 1.941 \n",
            "epoch: 16, acc: 0.654, loss: 2.268 (data_loss: 2.240, reg_loss: 0.028), lr: 0.009999920 validation, acc: 0.645, loss: 1.677 \n",
            "epoch: 17, acc: 0.655, loss: 1.819 (data_loss: 1.790, reg_loss: 0.029), lr: 0.009999915 validation, acc: 0.760, loss: 1.277 \n",
            "epoch: 18, acc: 0.670, loss: 1.651 (data_loss: 1.621, reg_loss: 0.031), lr: 0.009999910 validation, acc: 0.840, loss: 1.418 \n",
            "epoch: 19, acc: 0.799, loss: 1.667 (data_loss: 1.635, reg_loss: 0.032), lr: 0.009999905 validation, acc: 0.735, loss: 1.902 \n",
            "epoch: 20, acc: 0.619, loss: 2.200 (data_loss: 2.167, reg_loss: 0.033), lr: 0.009999900 validation, acc: 0.770, loss: 1.402 \n",
            "epoch: 21, acc: 0.687, loss: 1.782 (data_loss: 1.747, reg_loss: 0.035), lr: 0.009999895 validation, acc: 0.735, loss: 0.925 \n",
            "epoch: 22, acc: 0.644, loss: 1.371 (data_loss: 1.335, reg_loss: 0.036), lr: 0.009999890 validation, acc: 0.750, loss: 0.738 \n",
            "epoch: 23, acc: 0.747, loss: 0.835 (data_loss: 0.798, reg_loss: 0.037), lr: 0.009999885 validation, acc: 0.635, loss: 1.012 \n",
            "epoch: 24, acc: 0.609, loss: 1.295 (data_loss: 1.256, reg_loss: 0.039), lr: 0.009999880 validation, acc: 0.700, loss: 0.856 \n",
            "epoch: 25, acc: 0.625, loss: 1.262 (data_loss: 1.222, reg_loss: 0.040), lr: 0.009999875 validation, acc: 0.745, loss: 0.806 \n",
            "epoch: 26, acc: 0.724, loss: 0.882 (data_loss: 0.841, reg_loss: 0.041), lr: 0.009999870 validation, acc: 0.790, loss: 0.636 \n",
            "epoch: 27, acc: 0.659, loss: 1.257 (data_loss: 1.215, reg_loss: 0.042), lr: 0.009999865 validation, acc: 0.750, loss: 0.715 \n",
            "epoch: 28, acc: 0.787, loss: 0.751 (data_loss: 0.708, reg_loss: 0.043), lr: 0.009999860 validation, acc: 0.750, loss: 0.674 \n",
            "epoch: 29, acc: 0.747, loss: 0.822 (data_loss: 0.778, reg_loss: 0.044), lr: 0.009999855 validation, acc: 0.725, loss: 0.843 \n",
            "epoch: 30, acc: 0.739, loss: 0.987 (data_loss: 0.942, reg_loss: 0.045), lr: 0.009999850 validation, acc: 0.755, loss: 0.672 \n",
            "epoch: 31, acc: 0.797, loss: 0.654 (data_loss: 0.607, reg_loss: 0.046), lr: 0.009999845 validation, acc: 0.805, loss: 0.412 \n",
            "epoch: 32, acc: 0.795, loss: 0.654 (data_loss: 0.607, reg_loss: 0.047), lr: 0.009999840 validation, acc: 0.855, loss: 0.362 \n",
            "epoch: 33, acc: 0.815, loss: 0.614 (data_loss: 0.566, reg_loss: 0.048), lr: 0.009999835 validation, acc: 0.860, loss: 0.338 \n",
            "epoch: 34, acc: 0.695, loss: 0.847 (data_loss: 0.798, reg_loss: 0.049), lr: 0.009999830 validation, acc: 0.770, loss: 0.489 \n",
            "epoch: 35, acc: 0.674, loss: 0.919 (data_loss: 0.869, reg_loss: 0.050), lr: 0.009999825 validation, acc: 0.835, loss: 0.414 \n",
            "epoch: 36, acc: 0.751, loss: 0.754 (data_loss: 0.704, reg_loss: 0.050), lr: 0.009999820 validation, acc: 0.880, loss: 0.402 \n",
            "epoch: 37, acc: 0.839, loss: 0.723 (data_loss: 0.672, reg_loss: 0.051), lr: 0.009999815 validation, acc: 0.930, loss: 0.350 \n",
            "epoch: 38, acc: 0.890, loss: 0.531 (data_loss: 0.479, reg_loss: 0.052), lr: 0.009999810 validation, acc: 0.925, loss: 0.316 \n",
            "epoch: 39, acc: 0.814, loss: 0.640 (data_loss: 0.587, reg_loss: 0.053), lr: 0.009999805 validation, acc: 0.915, loss: 0.371 \n",
            "epoch: 40, acc: 0.939, loss: 0.385 (data_loss: 0.331, reg_loss: 0.054), lr: 0.009999800 validation, acc: 0.910, loss: 0.354 \n",
            "epoch: 41, acc: 0.914, loss: 0.401 (data_loss: 0.346, reg_loss: 0.055), lr: 0.009999795 validation, acc: 0.925, loss: 0.322 \n",
            "epoch: 42, acc: 0.764, loss: 1.571 (data_loss: 1.515, reg_loss: 0.056), lr: 0.009999790 validation, acc: 0.870, loss: 0.848 \n",
            "epoch: 43, acc: 0.741, loss: 1.543 (data_loss: 1.486, reg_loss: 0.057), lr: 0.009999785 validation, acc: 0.835, loss: 0.910 \n",
            "epoch: 44, acc: 0.794, loss: 1.404 (data_loss: 1.346, reg_loss: 0.058), lr: 0.009999780 validation, acc: 0.870, loss: 0.863 \n",
            "epoch: 45, acc: 0.791, loss: 1.332 (data_loss: 1.274, reg_loss: 0.058), lr: 0.009999775 validation, acc: 0.890, loss: 0.760 \n",
            "epoch: 46, acc: 0.852, loss: 1.136 (data_loss: 1.077, reg_loss: 0.059), lr: 0.009999770 validation, acc: 0.910, loss: 0.635 \n",
            "epoch: 47, acc: 0.863, loss: 0.958 (data_loss: 0.898, reg_loss: 0.060), lr: 0.009999765 validation, acc: 0.905, loss: 0.512 \n",
            "epoch: 48, acc: 0.853, loss: 0.951 (data_loss: 0.890, reg_loss: 0.061), lr: 0.009999760 validation, acc: 0.875, loss: 0.516 \n",
            "epoch: 49, acc: 0.811, loss: 0.826 (data_loss: 0.765, reg_loss: 0.061), lr: 0.009999755 validation, acc: 0.860, loss: 0.497 \n",
            "epoch: 50, acc: 0.811, loss: 0.788 (data_loss: 0.726, reg_loss: 0.061), lr: 0.009999750 validation, acc: 0.990, loss: 0.090 \n",
            "epoch: 51, acc: 0.889, loss: 0.554 (data_loss: 0.492, reg_loss: 0.062), lr: 0.009999745 validation, acc: 0.875, loss: 0.475 \n",
            "epoch: 52, acc: 0.790, loss: 0.936 (data_loss: 0.874, reg_loss: 0.062), lr: 0.009999740 validation, acc: 0.895, loss: 0.392 \n",
            "epoch: 53, acc: 0.881, loss: 0.603 (data_loss: 0.541, reg_loss: 0.062), lr: 0.009999735 validation, acc: 0.920, loss: 0.259 \n",
            "epoch: 54, acc: 0.895, loss: 0.404 (data_loss: 0.342, reg_loss: 0.063), lr: 0.009999730 validation, acc: 0.940, loss: 0.195 \n",
            "epoch: 55, acc: 0.898, loss: 0.638 (data_loss: 0.574, reg_loss: 0.063), lr: 0.009999725 validation, acc: 0.935, loss: 0.339 \n",
            "epoch: 56, acc: 0.816, loss: 1.702 (data_loss: 1.638, reg_loss: 0.063), lr: 0.009999720 validation, acc: 0.805, loss: 1.556 \n",
            "epoch: 57, acc: 0.802, loss: 1.563 (data_loss: 1.499, reg_loss: 0.063), lr: 0.009999715 validation, acc: 0.805, loss: 1.317 \n",
            "epoch: 58, acc: 0.852, loss: 1.618 (data_loss: 1.555, reg_loss: 0.063), lr: 0.009999710 validation, acc: 0.845, loss: 1.478 \n",
            "epoch: 59, acc: 0.850, loss: 1.573 (data_loss: 1.510, reg_loss: 0.063), lr: 0.009999705 validation, acc: 0.840, loss: 1.429 \n",
            "epoch: 60, acc: 0.859, loss: 1.587 (data_loss: 1.524, reg_loss: 0.063), lr: 0.009999700 validation, acc: 0.840, loss: 1.435 \n",
            "epoch: 61, acc: 0.870, loss: 1.288 (data_loss: 1.226, reg_loss: 0.062), lr: 0.009999695 validation, acc: 0.845, loss: 1.074 \n",
            "epoch: 62, acc: 0.871, loss: 0.775 (data_loss: 0.713, reg_loss: 0.061), lr: 0.009999690 validation, acc: 0.820, loss: 0.612 \n",
            "epoch: 63, acc: 0.757, loss: 1.077 (data_loss: 1.016, reg_loss: 0.061), lr: 0.009999685 validation, acc: 0.825, loss: 0.356 \n",
            "epoch: 64, acc: 0.876, loss: 0.357 (data_loss: 0.297, reg_loss: 0.060), lr: 0.009999680 validation, acc: 0.910, loss: 0.314 \n",
            "epoch: 65, acc: 0.930, loss: 0.311 (data_loss: 0.251, reg_loss: 0.060), lr: 0.009999675 validation, acc: 0.945, loss: 0.219 \n",
            "epoch: 66, acc: 0.969, loss: 0.154 (data_loss: 0.094, reg_loss: 0.060), lr: 0.009999670 validation, acc: 0.940, loss: 0.204 \n",
            "epoch: 67, acc: 0.882, loss: 0.603 (data_loss: 0.543, reg_loss: 0.059), lr: 0.009999665 validation, acc: 0.890, loss: 0.469 \n",
            "epoch: 68, acc: 0.862, loss: 0.604 (data_loss: 0.545, reg_loss: 0.059), lr: 0.009999660 validation, acc: 0.845, loss: 0.338 \n",
            "epoch: 69, acc: 0.640, loss: 1.505 (data_loss: 1.446, reg_loss: 0.059), lr: 0.009999655 validation, acc: 0.775, loss: 0.855 \n",
            "epoch: 70, acc: 0.742, loss: 1.278 (data_loss: 1.219, reg_loss: 0.059), lr: 0.009999650 validation, acc: 0.670, loss: 1.150 \n",
            "epoch: 71, acc: 0.612, loss: 1.782 (data_loss: 1.722, reg_loss: 0.060), lr: 0.009999645 validation, acc: 0.790, loss: 1.010 \n",
            "epoch: 72, acc: 0.814, loss: 1.120 (data_loss: 1.060, reg_loss: 0.060), lr: 0.009999640 validation, acc: 0.780, loss: 0.797 \n",
            "epoch: 73, acc: 0.684, loss: 1.563 (data_loss: 1.502, reg_loss: 0.061), lr: 0.009999635 validation, acc: 0.655, loss: 0.969 \n",
            "epoch: 74, acc: 0.601, loss: 2.589 (data_loss: 2.527, reg_loss: 0.062), lr: 0.009999630 validation, acc: 0.755, loss: 2.466 \n",
            "epoch: 75, acc: 0.669, loss: 2.514 (data_loss: 2.450, reg_loss: 0.064), lr: 0.009999625 validation, acc: 0.745, loss: 2.572 \n",
            "epoch: 76, acc: 0.756, loss: 1.765 (data_loss: 1.700, reg_loss: 0.065), lr: 0.009999620 validation, acc: 0.750, loss: 1.835 \n",
            "epoch: 77, acc: 0.740, loss: 1.318 (data_loss: 1.252, reg_loss: 0.067), lr: 0.009999615 validation, acc: 0.855, loss: 0.722 \n",
            "epoch: 78, acc: 0.833, loss: 1.077 (data_loss: 1.008, reg_loss: 0.068), lr: 0.009999610 validation, acc: 0.795, loss: 0.838 \n",
            "epoch: 79, acc: 0.788, loss: 1.093 (data_loss: 1.024, reg_loss: 0.070), lr: 0.009999605 validation, acc: 0.870, loss: 0.598 \n",
            "epoch: 80, acc: 0.841, loss: 0.934 (data_loss: 0.863, reg_loss: 0.071), lr: 0.009999600 validation, acc: 0.885, loss: 0.545 \n",
            "epoch: 81, acc: 0.873, loss: 0.819 (data_loss: 0.746, reg_loss: 0.073), lr: 0.009999595 validation, acc: 0.880, loss: 0.542 \n",
            "epoch: 82, acc: 0.863, loss: 0.844 (data_loss: 0.770, reg_loss: 0.074), lr: 0.009999590 validation, acc: 0.855, loss: 0.551 \n",
            "epoch: 83, acc: 0.837, loss: 0.876 (data_loss: 0.802, reg_loss: 0.075), lr: 0.009999585 validation, acc: 0.895, loss: 0.480 \n",
            "epoch: 84, acc: 0.859, loss: 0.802 (data_loss: 0.728, reg_loss: 0.075), lr: 0.009999580 validation, acc: 0.850, loss: 0.498 \n",
            "epoch: 85, acc: 0.793, loss: 0.922 (data_loss: 0.847, reg_loss: 0.075), lr: 0.009999575 validation, acc: 0.865, loss: 0.454 \n",
            "epoch: 86, acc: 0.839, loss: 0.714 (data_loss: 0.639, reg_loss: 0.075), lr: 0.009999570 validation, acc: 0.880, loss: 0.397 \n",
            "epoch: 87, acc: 0.813, loss: 0.864 (data_loss: 0.789, reg_loss: 0.075), lr: 0.009999565 validation, acc: 0.910, loss: 0.256 \n",
            "epoch: 88, acc: 0.877, loss: 0.457 (data_loss: 0.382, reg_loss: 0.074), lr: 0.009999560 validation, acc: 0.915, loss: 0.225 \n",
            "epoch: 89, acc: 0.843, loss: 0.409 (data_loss: 0.336, reg_loss: 0.074), lr: 0.009999555 validation, acc: 0.810, loss: 0.358 \n",
            "epoch: 90, acc: 0.833, loss: 0.546 (data_loss: 0.473, reg_loss: 0.073), lr: 0.009999550 validation, acc: 0.925, loss: 0.342 \n",
            "epoch: 91, acc: 0.905, loss: 0.413 (data_loss: 0.341, reg_loss: 0.072), lr: 0.009999545 validation, acc: 0.910, loss: 0.238 \n",
            "epoch: 92, acc: 0.879, loss: 0.424 (data_loss: 0.353, reg_loss: 0.071), lr: 0.009999540 validation, acc: 0.935, loss: 0.213 \n",
            "epoch: 93, acc: 0.935, loss: 0.394 (data_loss: 0.324, reg_loss: 0.070), lr: 0.009999535 validation, acc: 0.930, loss: 0.259 \n",
            "epoch: 94, acc: 0.856, loss: 0.420 (data_loss: 0.351, reg_loss: 0.069), lr: 0.009999530 validation, acc: 0.915, loss: 0.357 \n",
            "epoch: 95, acc: 0.787, loss: 1.174 (data_loss: 1.107, reg_loss: 0.067), lr: 0.009999525 validation, acc: 0.785, loss: 0.649 \n",
            "epoch: 96, acc: 0.834, loss: 0.492 (data_loss: 0.425, reg_loss: 0.066), lr: 0.009999520 validation, acc: 0.945, loss: 0.188 \n",
            "epoch: 97, acc: 0.941, loss: 0.249 (data_loss: 0.183, reg_loss: 0.066), lr: 0.009999515 validation, acc: 0.755, loss: 0.574 \n",
            "epoch: 98, acc: 0.783, loss: 0.794 (data_loss: 0.729, reg_loss: 0.065), lr: 0.009999510 validation, acc: 0.850, loss: 0.539 \n",
            "epoch: 99, acc: 0.843, loss: 0.822 (data_loss: 0.757, reg_loss: 0.064), lr: 0.009999505 validation, acc: 0.855, loss: 0.322 \n",
            "epoch: 100, acc: 0.901, loss: 0.341 (data_loss: 0.276, reg_loss: 0.064), lr: 0.009999500 validation, acc: 0.955, loss: 0.129 \n",
            "epoch: 101, acc: 0.964, loss: 0.203 (data_loss: 0.139, reg_loss: 0.064), lr: 0.009999495 validation, acc: 0.955, loss: 0.175 \n",
            "epoch: 102, acc: 0.814, loss: 0.865 (data_loss: 0.800, reg_loss: 0.065), lr: 0.009999490 validation, acc: 0.845, loss: 0.455 \n",
            "epoch: 103, acc: 0.843, loss: 0.508 (data_loss: 0.442, reg_loss: 0.065), lr: 0.009999485 validation, acc: 0.890, loss: 0.322 \n",
            "epoch: 104, acc: 0.916, loss: 0.393 (data_loss: 0.327, reg_loss: 0.066), lr: 0.009999480 validation, acc: 0.925, loss: 0.230 \n",
            "epoch: 105, acc: 0.949, loss: 0.303 (data_loss: 0.237, reg_loss: 0.067), lr: 0.009999475 validation, acc: 0.905, loss: 0.317 \n",
            "epoch: 106, acc: 0.886, loss: 0.460 (data_loss: 0.393, reg_loss: 0.068), lr: 0.009999470 validation, acc: 0.975, loss: 0.116 \n",
            "epoch: 107, acc: 0.961, loss: 0.181 (data_loss: 0.112, reg_loss: 0.068), lr: 0.009999465 validation, acc: 0.990, loss: 0.056 \n",
            "epoch: 108, acc: 0.958, loss: 0.180 (data_loss: 0.111, reg_loss: 0.069), lr: 0.009999460 validation, acc: 0.975, loss: 0.070 \n",
            "epoch: 109, acc: 0.970, loss: 0.188 (data_loss: 0.119, reg_loss: 0.069), lr: 0.009999455 validation, acc: 0.965, loss: 0.111 \n",
            "epoch: 110, acc: 0.884, loss: 0.355 (data_loss: 0.285, reg_loss: 0.070), lr: 0.009999450 validation, acc: 0.880, loss: 0.286 \n",
            "epoch: 111, acc: 0.902, loss: 0.342 (data_loss: 0.273, reg_loss: 0.070), lr: 0.009999445 validation, acc: 0.930, loss: 0.172 \n",
            "epoch: 112, acc: 0.940, loss: 0.252 (data_loss: 0.182, reg_loss: 0.070), lr: 0.009999440 validation, acc: 0.970, loss: 0.075 \n",
            "epoch: 113, acc: 0.894, loss: 0.606 (data_loss: 0.537, reg_loss: 0.070), lr: 0.009999435 validation, acc: 0.920, loss: 0.487 \n",
            "epoch: 114, acc: 0.851, loss: 0.781 (data_loss: 0.711, reg_loss: 0.070), lr: 0.009999430 validation, acc: 0.825, loss: 1.110 \n",
            "epoch: 115, acc: 0.778, loss: 2.025 (data_loss: 1.955, reg_loss: 0.070), lr: 0.009999425 validation, acc: 0.775, loss: 1.788 \n",
            "epoch: 116, acc: 0.765, loss: 2.145 (data_loss: 2.075, reg_loss: 0.070), lr: 0.009999420 validation, acc: 0.815, loss: 1.948 \n",
            "epoch: 117, acc: 0.870, loss: 1.100 (data_loss: 1.030, reg_loss: 0.070), lr: 0.009999415 validation, acc: 0.890, loss: 0.545 \n",
            "epoch: 118, acc: 0.884, loss: 0.507 (data_loss: 0.437, reg_loss: 0.070), lr: 0.009999410 validation, acc: 0.845, loss: 0.547 \n",
            "epoch: 119, acc: 0.878, loss: 0.718 (data_loss: 0.647, reg_loss: 0.071), lr: 0.009999405 validation, acc: 0.910, loss: 0.372 \n",
            "epoch: 120, acc: 0.880, loss: 0.702 (data_loss: 0.631, reg_loss: 0.071), lr: 0.009999400 validation, acc: 0.935, loss: 0.205 \n",
            "epoch: 121, acc: 0.906, loss: 0.414 (data_loss: 0.343, reg_loss: 0.072), lr: 0.009999395 validation, acc: 0.930, loss: 0.306 \n",
            "epoch: 122, acc: 0.878, loss: 0.757 (data_loss: 0.685, reg_loss: 0.072), lr: 0.009999390 validation, acc: 0.960, loss: 0.172 \n",
            "epoch: 123, acc: 0.878, loss: 0.740 (data_loss: 0.668, reg_loss: 0.072), lr: 0.009999385 validation, acc: 0.910, loss: 0.344 \n",
            "epoch: 124, acc: 0.888, loss: 0.561 (data_loss: 0.489, reg_loss: 0.072), lr: 0.009999380 validation, acc: 0.915, loss: 0.374 \n",
            "epoch: 125, acc: 0.790, loss: 1.918 (data_loss: 1.846, reg_loss: 0.072), lr: 0.009999375 validation, acc: 0.810, loss: 1.468 \n",
            "epoch: 126, acc: 0.803, loss: 1.804 (data_loss: 1.732, reg_loss: 0.072), lr: 0.009999370 validation, acc: 0.850, loss: 1.171 \n",
            "epoch: 127, acc: 0.786, loss: 1.890 (data_loss: 1.818, reg_loss: 0.072), lr: 0.009999365 validation, acc: 0.855, loss: 0.818 \n",
            "epoch: 128, acc: 0.849, loss: 1.149 (data_loss: 1.077, reg_loss: 0.072), lr: 0.009999360 validation, acc: 0.830, loss: 0.513 \n",
            "epoch: 129, acc: 0.832, loss: 0.803 (data_loss: 0.731, reg_loss: 0.072), lr: 0.009999355 validation, acc: 0.940, loss: 0.220 \n",
            "epoch: 130, acc: 0.952, loss: 0.291 (data_loss: 0.220, reg_loss: 0.072), lr: 0.009999350 validation, acc: 0.965, loss: 0.088 \n",
            "epoch: 131, acc: 0.953, loss: 0.252 (data_loss: 0.180, reg_loss: 0.071), lr: 0.009999345 validation, acc: 0.980, loss: 0.093 \n",
            "epoch: 132, acc: 0.971, loss: 0.223 (data_loss: 0.152, reg_loss: 0.071), lr: 0.009999340 validation, acc: 0.980, loss: 0.134 \n",
            "epoch: 133, acc: 0.968, loss: 0.220 (data_loss: 0.150, reg_loss: 0.070), lr: 0.009999335 validation, acc: 0.975, loss: 0.124 \n",
            "epoch: 134, acc: 0.936, loss: 0.368 (data_loss: 0.299, reg_loss: 0.070), lr: 0.009999330 validation, acc: 0.970, loss: 0.126 \n",
            "epoch: 135, acc: 0.941, loss: 0.341 (data_loss: 0.272, reg_loss: 0.069), lr: 0.009999325 validation, acc: 0.975, loss: 0.097 \n",
            "epoch: 136, acc: 0.957, loss: 0.240 (data_loss: 0.171, reg_loss: 0.069), lr: 0.009999320 validation, acc: 0.970, loss: 0.102 \n",
            "epoch: 137, acc: 0.958, loss: 0.240 (data_loss: 0.172, reg_loss: 0.068), lr: 0.009999315 validation, acc: 0.970, loss: 0.116 \n",
            "epoch: 138, acc: 0.947, loss: 0.291 (data_loss: 0.224, reg_loss: 0.068), lr: 0.009999310 validation, acc: 0.980, loss: 0.131 \n",
            "epoch: 139, acc: 0.982, loss: 0.165 (data_loss: 0.098, reg_loss: 0.067), lr: 0.009999305 validation, acc: 0.985, loss: 0.096 \n",
            "epoch: 140, acc: 0.983, loss: 0.177 (data_loss: 0.111, reg_loss: 0.066), lr: 0.009999300 validation, acc: 0.985, loss: 0.079 \n",
            "epoch: 141, acc: 0.974, loss: 0.201 (data_loss: 0.135, reg_loss: 0.066), lr: 0.009999295 validation, acc: 0.990, loss: 0.040 \n",
            "epoch: 142, acc: 0.988, loss: 0.154 (data_loss: 0.089, reg_loss: 0.065), lr: 0.009999290 validation, acc: 0.980, loss: 0.074 \n",
            "epoch: 143, acc: 0.970, loss: 0.187 (data_loss: 0.122, reg_loss: 0.065), lr: 0.009999285 validation, acc: 0.985, loss: 0.037 \n",
            "epoch: 144, acc: 0.982, loss: 0.165 (data_loss: 0.101, reg_loss: 0.064), lr: 0.009999280 validation, acc: 0.985, loss: 0.054 \n",
            "epoch: 145, acc: 0.977, loss: 0.168 (data_loss: 0.105, reg_loss: 0.063), lr: 0.009999275 validation, acc: 0.970, loss: 0.105 \n",
            "epoch: 146, acc: 0.956, loss: 0.231 (data_loss: 0.169, reg_loss: 0.062), lr: 0.009999270 validation, acc: 0.975, loss: 0.086 \n",
            "epoch: 147, acc: 0.981, loss: 0.154 (data_loss: 0.092, reg_loss: 0.061), lr: 0.009999265 validation, acc: 0.980, loss: 0.089 \n",
            "epoch: 148, acc: 0.987, loss: 0.133 (data_loss: 0.073, reg_loss: 0.060), lr: 0.009999260 validation, acc: 0.980, loss: 0.086 \n",
            "epoch: 149, acc: 0.993, loss: 0.123 (data_loss: 0.064, reg_loss: 0.059), lr: 0.009999255 validation, acc: 0.980, loss: 0.086 \n",
            "epoch: 150, acc: 0.890, loss: 0.858 (data_loss: 0.800, reg_loss: 0.058), lr: 0.009999250 validation, acc: 0.945, loss: 0.204 \n",
            "epoch: 151, acc: 0.965, loss: 0.208 (data_loss: 0.151, reg_loss: 0.057), lr: 0.009999245 validation, acc: 0.945, loss: 0.198 \n",
            "epoch: 152, acc: 0.964, loss: 0.218 (data_loss: 0.162, reg_loss: 0.056), lr: 0.009999240 validation, acc: 0.970, loss: 0.156 \n",
            "epoch: 153, acc: 0.984, loss: 0.137 (data_loss: 0.082, reg_loss: 0.055), lr: 0.009999235 validation, acc: 0.980, loss: 0.120 \n",
            "epoch: 154, acc: 0.908, loss: 0.480 (data_loss: 0.427, reg_loss: 0.053), lr: 0.009999230 validation, acc: 0.965, loss: 0.159 \n",
            "epoch: 155, acc: 0.902, loss: 0.388 (data_loss: 0.336, reg_loss: 0.052), lr: 0.009999225 validation, acc: 0.970, loss: 0.103 \n",
            "epoch: 156, acc: 0.963, loss: 0.220 (data_loss: 0.169, reg_loss: 0.051), lr: 0.009999220 validation, acc: 0.950, loss: 0.171 \n",
            "epoch: 157, acc: 0.964, loss: 0.193 (data_loss: 0.142, reg_loss: 0.051), lr: 0.009999215 validation, acc: 0.905, loss: 0.270 \n",
            "epoch: 158, acc: 0.834, loss: 0.659 (data_loss: 0.608, reg_loss: 0.051), lr: 0.009999210 validation, acc: 0.975, loss: 0.073 \n",
            "epoch: 159, acc: 0.925, loss: 0.299 (data_loss: 0.247, reg_loss: 0.051), lr: 0.009999205 validation, acc: 0.960, loss: 0.193 \n",
            "epoch: 160, acc: 0.874, loss: 0.758 (data_loss: 0.706, reg_loss: 0.052), lr: 0.009999200 validation, acc: 0.960, loss: 0.213 \n",
            "epoch: 161, acc: 0.933, loss: 0.348 (data_loss: 0.296, reg_loss: 0.053), lr: 0.009999195 validation, acc: 0.915, loss: 0.401 \n",
            "epoch: 162, acc: 0.827, loss: 0.734 (data_loss: 0.680, reg_loss: 0.054), lr: 0.009999190 validation, acc: 0.815, loss: 0.639 \n",
            "epoch: 163, acc: 0.858, loss: 0.562 (data_loss: 0.507, reg_loss: 0.056), lr: 0.009999185 validation, acc: 0.855, loss: 0.819 \n",
            "epoch: 164, acc: 0.862, loss: 0.730 (data_loss: 0.672, reg_loss: 0.057), lr: 0.009999180 validation, acc: 0.895, loss: 0.645 \n",
            "epoch: 165, acc: 0.881, loss: 0.774 (data_loss: 0.715, reg_loss: 0.059), lr: 0.009999175 validation, acc: 0.895, loss: 0.636 \n",
            "epoch: 166, acc: 0.918, loss: 0.610 (data_loss: 0.550, reg_loss: 0.060), lr: 0.009999170 validation, acc: 0.930, loss: 0.365 \n",
            "epoch: 167, acc: 0.886, loss: 0.798 (data_loss: 0.736, reg_loss: 0.062), lr: 0.009999165 validation, acc: 0.950, loss: 0.123 \n",
            "epoch: 168, acc: 0.949, loss: 0.333 (data_loss: 0.270, reg_loss: 0.064), lr: 0.009999160 validation, acc: 0.965, loss: 0.082 \n",
            "epoch: 169, acc: 0.965, loss: 0.311 (data_loss: 0.245, reg_loss: 0.065), lr: 0.009999155 validation, acc: 0.955, loss: 0.200 \n",
            "epoch: 170, acc: 0.960, loss: 0.280 (data_loss: 0.213, reg_loss: 0.067), lr: 0.009999150 validation, acc: 0.950, loss: 0.237 \n",
            "epoch: 171, acc: 0.927, loss: 0.408 (data_loss: 0.340, reg_loss: 0.069), lr: 0.009999145 validation, acc: 0.990, loss: 0.126 \n",
            "epoch: 172, acc: 0.954, loss: 0.348 (data_loss: 0.278, reg_loss: 0.070), lr: 0.009999140 validation, acc: 0.965, loss: 0.223 \n",
            "epoch: 173, acc: 0.910, loss: 0.408 (data_loss: 0.336, reg_loss: 0.071), lr: 0.009999135 validation, acc: 0.945, loss: 0.276 \n",
            "epoch: 174, acc: 0.954, loss: 0.373 (data_loss: 0.301, reg_loss: 0.073), lr: 0.009999130 validation, acc: 0.970, loss: 0.177 \n",
            "epoch: 175, acc: 0.968, loss: 0.258 (data_loss: 0.184, reg_loss: 0.074), lr: 0.009999125 validation, acc: 0.970, loss: 0.213 \n",
            "epoch: 176, acc: 0.971, loss: 0.256 (data_loss: 0.181, reg_loss: 0.075), lr: 0.009999120 validation, acc: 0.980, loss: 0.118 \n",
            "epoch: 177, acc: 0.960, loss: 0.350 (data_loss: 0.275, reg_loss: 0.075), lr: 0.009999115 validation, acc: 0.975, loss: 0.101 \n",
            "epoch: 178, acc: 0.972, loss: 0.242 (data_loss: 0.166, reg_loss: 0.076), lr: 0.009999110 validation, acc: 0.955, loss: 0.309 \n",
            "epoch: 179, acc: 0.963, loss: 0.284 (data_loss: 0.208, reg_loss: 0.077), lr: 0.009999105 validation, acc: 0.945, loss: 0.497 \n",
            "epoch: 180, acc: 0.947, loss: 0.444 (data_loss: 0.367, reg_loss: 0.077), lr: 0.009999100 validation, acc: 0.960, loss: 0.221 \n",
            "epoch: 181, acc: 0.955, loss: 0.291 (data_loss: 0.213, reg_loss: 0.078), lr: 0.009999095 validation, acc: 0.965, loss: 0.096 \n",
            "epoch: 182, acc: 0.962, loss: 0.252 (data_loss: 0.174, reg_loss: 0.078), lr: 0.009999090 validation, acc: 0.975, loss: 0.065 \n",
            "epoch: 183, acc: 0.969, loss: 0.224 (data_loss: 0.146, reg_loss: 0.078), lr: 0.009999085 validation, acc: 0.990, loss: 0.021 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR0u0Jm7QCrw"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KNnDUP_U8Xn",
        "outputId": "1d91d69e-0d95-45cf-d380-3d7b990dad6e"
      },
      "source": [
        "print(np.mean(acc_cache))"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8189297297297297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NbXMisqQKqF",
        "outputId": "14a47466-768e-409c-e6c4-11efb951b5d7"
      },
      "source": [
        "for milestone in summary:\n",
        "  print(milestone)"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model hit 80% validation accuracy in 18 epochs\n",
            "Model hit 85% validation accuracy in 32 epochs\n",
            "Model hit 90% validation accuracy in 37 epochs\n",
            "Model hit 95% validation accuracy in 50 epochs\n",
            "Model hit 97.5% validation accuracy in 50 epochs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rVqT3yaXS5k"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smwSXsZVU8Xo",
        "outputId": "ec9bc859-faff-40b5-a293-57e1a037b1fc"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(y_test)\n",
        "\n",
        "dense1.forward(X_test)\n",
        "\n",
        "activation1.forward(dense1.output)\n",
        "test_train_mean = activation1.output\n",
        "print(test_train_mean.shape)\n",
        "\n",
        "dropout1.infrence(activation1.output,y_test)\n",
        "\n",
        "dense2.forward(dropout1.output)\n",
        "\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "dense3.forward(activation2.output)\n",
        "\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "dense4.forward(activation3.output)\n",
        "\n",
        "activation4.forward(dense4.output)\n",
        "\n",
        "# Calculate the data loss\n",
        "loss = loss_function.calculate(activation4.output, y_test)\n",
        "\n",
        "predictions = activation4.predictions(activation4.output)\n",
        "testaccuracy = accuracy.calculate(predictions, y_test)\n",
        "\n",
        "print(f'training, acc: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 128)\n",
            "training, acc: 0.995, loss: 0.015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmp-61GRtNcD",
        "outputId": "a03c1525-e14d-4c09-fb1d-4f8a57e0cb33"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(y)\n",
        "\n",
        "dense1.forward(X)\n",
        "\n",
        "activation1.forward(dense1.output)\n",
        "train_train_mean = activation1.output\n",
        "\n",
        "dropout1.infrence(activation1.output,y)\n",
        "\n",
        "dense2.forward(dropout1.output)\n",
        "\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "dense3.forward(activation2.output)\n",
        "\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "dense4.forward(activation3.output)\n",
        "\n",
        "activation4.forward(dense4.output)\n",
        "\n",
        "# Calculate the data loss\n",
        "loss = loss_function.calculate(activation4.output, y)\n",
        "\n",
        "predictions = activation4.predictions(activation4.output)\n",
        "testaccuracy = accuracy.calculate(predictions, y)\n",
        "\n",
        "print(f'training, acc: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training, acc: 0.975, loss: 0.169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k0Ve2M0bPG3"
      },
      "source": [
        "training_diff = []\n",
        "testing_diff = []\n",
        "combined_diff = []"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MByL_RwvlIx3"
      },
      "source": [
        "Individual Training Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTOnqnDXa0ME",
        "outputId": "e6e6d129-878d-4abd-9219-7588460d8380"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "for classes, (X_sorted_lists, y_sorted_lists) in enumerate(zip(sorted_x, sorted_y)):\n",
        "  accuracy.init(y_sorted_lists)\n",
        "  #print(sorted_y[y_sorted_lists].shape)\n",
        "  #print(sorted_x[X_sorted_lists].shape)\n",
        "  dense1.forward(sorted_x[X_sorted_lists])\n",
        "\n",
        "  activation1.forward(dense1.output)\n",
        "\n",
        "  trainmean = np.mean(activation1.output, axis=0)\n",
        "  \n",
        "  training_diff.append(trainmean)\n",
        "\n",
        "  dropout1.infrence(activation1.output,sorted_y[y_sorted_lists])\n",
        "\n",
        "  dense2.forward(dropout1.output)\n",
        "\n",
        "  activation2.forward(dense2.output)\n",
        "\n",
        "  dense3.forward(activation2.output)\n",
        "\n",
        "  activation3.forward(dense3.output)\n",
        "\n",
        "  dense4.forward(activation3.output)\n",
        "\n",
        "  activation4.forward(dense4.output)\n",
        "  # Calculate the data loss\n",
        "  loss = loss_function.calculate(activation4.output, sorted_y[y_sorted_lists])\n",
        "\n",
        "  predictions = activation4.predictions(activation4.output)\n",
        "  testaccuracy = accuracy.calculate(predictions, sorted_y[y_sorted_lists])\n",
        "\n",
        "  print(f'{fashion_mnist_labels[classes]} Accuracy: {testaccuracy:.3f}, loss: {loss:.3f}')\n",
        "\n"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T-shirt/top Accuracy: 0.968, loss: 0.196\n",
            "Trouser Accuracy: 0.030, loss: 15.550\n",
            "Pullover Accuracy: 0.000, loss: 16.118\n",
            "Dress Accuracy: 0.010, loss: 15.962\n",
            "Coat Accuracy: 0.000, loss: 16.118\n",
            "Sandal Accuracy: 0.000, loss: 16.118\n",
            "Shirt Accuracy: 0.000, loss: 16.118\n",
            "Sneaker Accuracy: 0.000, loss: 16.118\n",
            "Bag Accuracy: 0.021, loss: 15.786\n",
            "Ankle boot Accuracy: 0.011, loss: 15.943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXDmVgdrlNit"
      },
      "source": [
        "Individual Testing Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd-bplUflP1o",
        "outputId": "f786ac5b-9c13-4e1a-f90c-79eed9c46dd4"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "for classes, (X_sorted_lists, y_sorted_lists) in enumerate(zip(sorted_x_test, sorted_y_test)):\n",
        "  accuracy.init(y_sorted_lists)\n",
        "  #print(sorted_y[y_sorted_lists].shape)\n",
        "  #print(sorted_x[X_sorted_lists].shape)\n",
        "  dense1.forward(sorted_x_test[X_sorted_lists])\n",
        "\n",
        "  activation1.forward(dense1.output)\n",
        "\n",
        "  testmean = np.mean(activation1.output, axis=0)\n",
        "  testing_diff.append(testmean)\n",
        "  dropout1.infrence(activation1.output,sorted_y_test[y_sorted_lists])\n",
        "\n",
        "  dense2.forward(dropout1.output)\n",
        "\n",
        "  activation2.forward(dense2.output)\n",
        "\n",
        "  dense3.forward(activation2.output)\n",
        "\n",
        "  activation3.forward(dense3.output)\n",
        "\n",
        "  dense4.forward(activation3.output)\n",
        "\n",
        "  activation4.forward(dense4.output)\n",
        "  # Calculate the data loss\n",
        "  loss = loss_function.calculate(activation4.output, sorted_y_test[y_sorted_lists])\n",
        "\n",
        "  predictions = activation4.predictions(activation4.output)\n",
        "  testaccuracy = accuracy.calculate(predictions, sorted_y_test[y_sorted_lists])\n",
        "\n",
        "  print(f'{fashion_mnist_labels[classes]} Accuracy: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 345,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "T-shirt/top Accuracy: 1.000, loss: 0.001\n",
            "Trouser Accuracy: 0.037, loss: 15.521\n",
            "Pullover Accuracy: 0.000, loss: 16.118\n",
            "Dress Accuracy: 0.000, loss: 16.118\n",
            "Coat Accuracy: 1.000, loss: 0.000\n",
            "Sandal Accuracy: 0.125, loss: 8.351\n",
            "Shirt Accuracy: 0.312, loss: 11.081\n",
            "Sneaker Accuracy: 0.250, loss: 10.615\n",
            "Bag Accuracy: 0.056, loss: 15.223\n",
            "Ankle boot Accuracy: 1.000, loss: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLqIMUmEVx65",
        "outputId": "5e1b7c8f-d37a-4553-81c0-70ad070b83b3"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "test_label_rand_arry = np.random.randint(0,9,(128,))\n",
        "test_input_rand_arry = np.random.rand(128)\n",
        "\n",
        "train_label_rand_arry = np.random.randint(0,9,(128,))\n",
        "train_input_rand_arry = np.random.rand(128)\n",
        "#print(test_rand_arry)\n",
        "\n",
        "testing_inputs = np.random.randint(0,10,(1000,128))\n",
        "testing_label = np.random.randint(0,9,(1000,))\n",
        "\n",
        "#print(testing_inputs)\n",
        "#print(testing_diff)\n",
        "\n",
        "#-----------------\n",
        "\n",
        "def new_Dropout(X_test, y_test, X, y, rate):\n",
        "  idx = np.argsort(y_test)\n",
        "  X_test_sorted = X_test[idx]\n",
        "  y_test_sorted = y_test[idx]\n",
        "\n",
        "  idx2 = np.argsort(y)\n",
        "  X_train_sorted = X[idx2]\n",
        "  y_train_sorted = y[idx2]\n",
        "\n",
        "  sorted_x = {}\n",
        "  sorted_y = {}\n",
        "  for classes in range(len(set(y))):\n",
        "    sorted_x[\"class_{0}\".format(classes)] = X[y == classes]\n",
        "    sorted_y[\"label_{0}\".format(classes)] = y[y == classes]\n",
        "\n",
        "  sorted_x_test = {}\n",
        "  sorted_y_test = {}\n",
        "  for classes in range(len(set(y))):\n",
        "    sorted_x_test[\"class_{0}\".format(classes)] = X_test[y_test == classes]\n",
        "    sorted_y_test[\"label_{0}\".format(classes)] = y_test[y_test == classes]\n",
        "\n",
        "  differnce_classes = {}\n",
        "  diff_test = {}\n",
        "  for i, classes, test_classes in zip(range(len(set(y))), sorted_x, sorted_x_test):\n",
        "    differnce_classes[\"diff_{0}\".format(i)] = np.mean(sorted_x[classes], axis=0) - np.mean(sorted_x_test[classes], axis=0)\n",
        "    diff_test[\"diff_{0}\".format(i)] = np.mean(sorted_x[classes], axis=0) - np.mean(sorted_x_test[classes], axis=0)\n",
        "\n",
        "\n",
        "  diff_mask = {}\n",
        "  for i, classes, test_classes, diff in zip(range(len(set(y))), sorted_x, sorted_x_test, differnce_classes):\n",
        "    ind = np.argpartition(differnce_classes[diff], -round(len(X[0]) * rate))[-round(len(X[0]) * rate):]\n",
        "    mask = np.ones(np.mean(sorted_x[classes],axis=0).shape, dtype=bool)\n",
        "    mask[ind] = False\n",
        "    differnce_classes[diff][~mask] = 0\n",
        "    differnce_classes[diff][mask] = 1\n",
        "    diff_mask[\"mask_{0}\".format(i)] = differnce_classes[diff]\n",
        "\n",
        "  binary_mask = np.empty(shape=X.shape)\n",
        "  for i, input, label in zip(range(len(X)), X, y):\n",
        "    for true, diff in zip(range(len(set(y))),diff_mask):\n",
        "      if label == true:\n",
        "        binary_mask[i] =  diff_mask[diff]\n",
        "\n",
        "  output = binary_mask * X\n",
        "\n",
        "  print(diff_test['diff_1'])\n",
        "\n",
        "  return output\n",
        "\n",
        "print(training_diff[1]-testing_diff[1])\n",
        "test = new_Dropout(X=train_train_mean, y=y, X_test=test_train_mean, y_test=y_test, rate=0.2)"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8.95635525e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  6.07417520e-02  0.00000000e+00  8.63927809e-02\n",
            " -2.47626484e-01  2.88361093e-02  7.12120811e-04  1.94795767e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -2.01436607e-01 -3.55329717e-01\n",
            "  2.35850283e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  3.90484552e-01  0.00000000e+00  0.00000000e+00  1.76388666e-01\n",
            "  0.00000000e+00  8.17478582e-03  0.00000000e+00 -5.29768504e-02\n",
            "  2.21745939e-01  0.00000000e+00  0.00000000e+00  7.88138196e-03\n",
            "  0.00000000e+00  0.00000000e+00  9.33669250e-02  1.11823277e-02\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00 -1.13226046e-03  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  6.34985269e-03  0.00000000e+00\n",
            "  5.21989814e-03  0.00000000e+00  7.11153589e-02  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -1.82590179e-01  3.34871769e-01\n",
            " -6.41034198e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  2.45028812e-01  2.55387186e-03  0.00000000e+00  1.57242748e-01\n",
            "  8.13871434e-01  0.00000000e+00 -1.24310262e-01  0.00000000e+00\n",
            "  0.00000000e+00  4.25551331e-01  5.18601440e-01  0.00000000e+00\n",
            "  0.00000000e+00 -1.26260057e-01  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  3.41109270e-03  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  3.91636649e-03  0.00000000e+00  6.83970181e-01\n",
            "  0.00000000e+00 -7.22833182e-01  0.00000000e+00  1.93862026e-03\n",
            "  0.00000000e+00 -1.72962886e-01  0.00000000e+00 -2.64798847e-01\n",
            "  0.00000000e+00  4.48048333e-02  5.06071723e-01 -2.14871119e-01\n",
            "  2.51019531e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  3.18949176e-01  0.00000000e+00  0.00000000e+00\n",
            "  9.97305219e-01  6.06551876e-03  0.00000000e+00  4.77041119e-03\n",
            "  0.00000000e+00  5.50184628e-02  0.00000000e+00  1.06549628e-01\n",
            "  0.00000000e+00  1.08419638e-03  7.93262408e-02 -7.60735850e-02\n",
            "  4.03894295e-01  0.00000000e+00  6.24511409e-02 -3.96710068e-02\n",
            "  0.00000000e+00  0.00000000e+00  1.01657533e-01  0.00000000e+00]\n",
            "[ 8.95635525e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  6.07417520e-02  0.00000000e+00  8.63927809e-02\n",
            " -2.47626484e-01  2.88361093e-02  7.12120811e-04  1.94795767e-01\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -2.01436607e-01 -3.55329717e-01\n",
            "  2.35850283e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  3.90484552e-01  0.00000000e+00  0.00000000e+00  1.76388666e-01\n",
            "  0.00000000e+00  8.17478582e-03  0.00000000e+00 -5.29768504e-02\n",
            "  2.21745939e-01  0.00000000e+00  0.00000000e+00  7.88138196e-03\n",
            "  0.00000000e+00  0.00000000e+00  9.33669250e-02  1.11823277e-02\n",
            "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00 -1.13226046e-03  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00  6.34985269e-03  0.00000000e+00\n",
            "  5.21989814e-03  0.00000000e+00  7.11153589e-02  0.00000000e+00\n",
            "  0.00000000e+00  0.00000000e+00 -1.82590179e-01  3.34871769e-01\n",
            " -6.41034198e-02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  2.45028812e-01  2.55387186e-03  0.00000000e+00  1.57242748e-01\n",
            "  8.13871434e-01  0.00000000e+00 -1.24310262e-01  0.00000000e+00\n",
            "  0.00000000e+00  4.25551331e-01  5.18601440e-01  0.00000000e+00\n",
            "  0.00000000e+00 -1.26260057e-01  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  3.41109270e-03  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  3.91636649e-03  0.00000000e+00  6.83970181e-01\n",
            "  0.00000000e+00 -7.22833182e-01  0.00000000e+00  1.93862026e-03\n",
            "  0.00000000e+00 -1.72962886e-01  0.00000000e+00 -2.64798847e-01\n",
            "  0.00000000e+00  4.48048333e-02  5.06071723e-01 -2.14871119e-01\n",
            "  2.51019531e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  3.18949176e-01  0.00000000e+00  0.00000000e+00\n",
            "  9.97305219e-01  6.06551876e-03  0.00000000e+00  4.77041119e-03\n",
            "  0.00000000e+00  5.50184628e-02  0.00000000e+00  1.06549628e-01\n",
            "  0.00000000e+00  1.08419638e-03  7.93262408e-02 -7.60735850e-02\n",
            "  4.03894295e-01  0.00000000e+00  6.24511409e-02 -3.96710068e-02\n",
            "  0.00000000e+00  0.00000000e+00  1.01657533e-01  0.00000000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2u-O8oNZ0qA"
      },
      "source": [
        "# Full mnist test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMfBGUHeZ4L5",
        "outputId": "8af1625c-36c0-46f6-dc10-ae1d33d23997"
      },
      "source": [
        "(input, label), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Label index to label name relation\n",
        "fashion_mnist_labels = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}\n",
        "\n",
        "\n",
        "# Shuffle the training dataset\n",
        "keys = np.array(range(input.shape[0]))\n",
        "np.random.shuffle(keys)\n",
        "input = input[keys]\n",
        "label = label[keys]\n",
        "\n",
        "\n",
        "# Scale and reshape samples\n",
        "input = (input.reshape(input.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
        "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) -\n",
        "             127.5) / 127.5\n",
        "\n",
        "\n",
        "\n",
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(label)\n",
        "\n",
        "dense1.forward(input)\n",
        "\n",
        "activation1.forward(dense1.output)\n",
        "train_train_mean = activation1.output\n",
        "\n",
        "dropout1.infrence(activation1.output,label)\n",
        "\n",
        "dense2.forward(dropout1.output)\n",
        "\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "dense3.forward(activation2.output)\n",
        "\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "dense4.forward(activation3.output)\n",
        "\n",
        "activation4.forward(dense4.output)\n",
        "\n",
        "# Calculate the data loss\n",
        "loss = loss_function.calculate(activation4.output, label)\n",
        "\n",
        "predictions = activation4.predictions(activation4.output)\n",
        "testaccuracy = accuracy.calculate(predictions, label)\n",
        "\n",
        "print(f'training, acc: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training, acc: 0.967, loss: 0.193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRXGM4hyXmr7"
      },
      "source": [
        "Plotting Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "h5c5xUTNXk2v",
        "outputId": "f1315ff1-300b-492b-f5c7-fefbd13e06a8"
      },
      "source": [
        "plt.plot(epoch_cache, val_loss_cache, label='Validation Loss')\n",
        "plt.plot(epoch_cache, loss_cache, label='Training Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_cache, val_acc_cache, label='Validation Accuracy')\n",
        "plt.plot(epoch_cache, acc_cache, label='Training Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(epoch_cache, lr_cache, label='LR')\n",
        "plt.title('Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.show()"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
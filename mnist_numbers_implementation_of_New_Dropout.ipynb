{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist numbers implementation of New_Dropout.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "4a10260d53feadc3aac998a3ba3a60b43aac84189bada71a196791e24306642d"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 64-bit ('AITraining': virtualenvwrapper)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoshuaShunk/NSDropout/blob/main/mnist_numbers_implementation_of_New_Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtYgI3SFHqm4"
      },
      "source": [
        "# MNIST Numbers Implementation of My New Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2GytIidUnpd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aLxFoLMU2jC"
      },
      "source": [
        "np.set_printoptions(threshold=np.inf)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06HD9nTuEVHD"
      },
      "source": [
        "np.random.seed(seed=22) #Random seed used for comparison between old dropout"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cag8ZraxEZbF",
        "outputId": "232ad3d5-1b4c-4094-97e5-a69318923768"
      },
      "source": [
        "print(np.random.random(size=3)) #Check that seeds line up"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20846054 0.48168106 0.42053804]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NkY3EiBU4tR",
        "cellView": "form"
      },
      "source": [
        "#@title Load Layers (Credit to Harrison Kinsley & Daniel Kukiela for raw python implementation)\n",
        "\n",
        "# Dense layer\n",
        "class Layer_Dense:\n",
        "\n",
        "    # Layer initialization\n",
        "    def __init__(self, n_inputs, n_neurons,\n",
        "                 weight_regularizer_l1=0, weight_regularizer_l2=0,\n",
        "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
        "        # Initialize weights and biases\n",
        "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
        "        self.biases = np.zeros((1, n_neurons))\n",
        "        # Set regularization strength\n",
        "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
        "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
        "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
        "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs, weights and biases\n",
        "        self.output = np.dot(inputs, self.weights) + self.biases\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradients on parameters\n",
        "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
        "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "\n",
        "        # Gradients on regularization\n",
        "        # L1 on weights\n",
        "        if self.weight_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.weights)\n",
        "            dL1[self.weights < 0] = -1\n",
        "            self.dweights += self.weight_regularizer_l1 * dL1\n",
        "        # L2 on weights\n",
        "        if self.weight_regularizer_l2 > 0:\n",
        "            self.dweights += 2 * self.weight_regularizer_l2 * \\\n",
        "                             self.weights\n",
        "        # L1 on biases\n",
        "        if self.bias_regularizer_l1 > 0:\n",
        "            dL1 = np.ones_like(self.biases)\n",
        "            dL1[self.biases < 0] = -1\n",
        "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
        "        # L2 on biases\n",
        "        if self.bias_regularizer_l2 > 0:\n",
        "            self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
        "                            self.biases\n",
        "\n",
        "        # Gradient on values\n",
        "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "# ReLU activation\n",
        "\n",
        "\n",
        "class Activation_ReLU:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "        # Calculate output values from inputs\n",
        "        self.output = np.maximum(0, inputs)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Since we need to modify original variable,\n",
        "        # let's make a copy of values first\n",
        "        self.dinputs = dvalues.copy()\n",
        "\n",
        "        # Zero gradient where input values were negative\n",
        "        self.dinputs[self.inputs <= 0] = 0\n",
        "\n",
        "\n",
        "# Softmax activation\n",
        "class Activation_Softmax:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Remember input values\n",
        "        self.inputs = inputs\n",
        "\n",
        "        # Get unnormalized probabilities\n",
        "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
        "                                            keepdims=True))\n",
        "        # Normalize them for each sample\n",
        "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
        "                                            keepdims=True)\n",
        "\n",
        "        self.output = probabilities\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Create uninitialized array\n",
        "        self.dinputs = np.empty_like(dvalues)\n",
        "\n",
        "        # Enumerate outputs and gradients\n",
        "        for index, (single_output, single_dvalues) in \\\n",
        "                enumerate(zip(self.output, dvalues)):\n",
        "            # Flatten output array\n",
        "            single_output = single_output.reshape(-1, 1)\n",
        "\n",
        "            # Calculate Jacobian matrix of the output\n",
        "            jacobian_matrix = np.diagflat(single_output) - \\\n",
        "                              np.dot(single_output, single_output.T)\n",
        "            # Calculate sample-wise gradient\n",
        "            # and add it to the array of sample gradients\n",
        "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
        "                                         single_dvalues)\n",
        "    def predictions(self, outputs):\n",
        "        return np.argmax(outputs, axis=1)\n",
        "\n",
        "\n",
        "# Sigmoid activation\n",
        "class Activation_Sigmoid:\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Save input and calculate/save output\n",
        "        # of the sigmoid function\n",
        "        self.inputs = inputs\n",
        "        self.output = 1 / (1 + np.exp(-inputs))\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Derivative - calculates from output of the sigmoid function\n",
        "        self.dinputs = dvalues * (1 - self.output) * self.output\n",
        "\n",
        "\n",
        "# SGD optimizer\n",
        "class Optimizer_SGD:\n",
        "\n",
        "    # Initialize optimizer - set settings,\n",
        "    # learning rate of 1. is default for this optimizer\n",
        "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.momentum = momentum\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If we use momentum\n",
        "        if self.momentum:\n",
        "\n",
        "            # If layer does not contain momentum arrays, create them\n",
        "            # filled with zeros\n",
        "            if not hasattr(layer, 'weight_momentums'):\n",
        "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "                # If there is no momentum array for weights\n",
        "                # The array doesn't exist for biases yet either.\n",
        "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "\n",
        "            # Build weight updates with momentum - take previous\n",
        "            # updates multiplied by retain factor and update with\n",
        "            # current gradients\n",
        "            weight_updates = \\\n",
        "                self.momentum * layer.weight_momentums - \\\n",
        "                self.current_learning_rate * layer.dweights\n",
        "            layer.weight_momentums = weight_updates\n",
        "\n",
        "            # Build bias updates\n",
        "            bias_updates = \\\n",
        "                self.momentum * layer.bias_momentums - \\\n",
        "                self.current_learning_rate * layer.dbiases\n",
        "            layer.bias_momentums = bias_updates\n",
        "\n",
        "        # Vanilla SGD updates (as before momentum update)\n",
        "        else:\n",
        "            weight_updates = -self.current_learning_rate * \\\n",
        "                             layer.dweights\n",
        "            bias_updates = -self.current_learning_rate * \\\n",
        "                           layer.dbiases\n",
        "\n",
        "        # Update weights and biases using either\n",
        "        # vanilla or momentum updates\n",
        "        layer.weights += weight_updates\n",
        "        layer.biases += bias_updates\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adagrad optimizer\n",
        "class Optimizer_Adagrad:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache += layer.dweights ** 2\n",
        "        layer.bias_cache += layer.dbiases ** 2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# RMSprop optimizer\n",
        "class Optimizer_RMSprop:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
        "                 rho=0.9):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.rho = rho\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.rho * layer.weight_cache + \\\n",
        "                             (1 - self.rho) * layer.dweights ** 2\n",
        "        layer.bias_cache = self.rho * layer.bias_cache + \\\n",
        "                           (1 - self.rho) * layer.dbiases ** 2\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         layer.dweights / \\\n",
        "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        layer.dbiases / \\\n",
        "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Adam optimizer\n",
        "class Optimizer_Adam:\n",
        "\n",
        "    # Initialize optimizer - set settings\n",
        "    def __init__(self, learning_rate=0.02, decay=0., epsilon=1e-7,\n",
        "                 beta_1=0.9, beta_2=0.999):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.current_learning_rate = learning_rate\n",
        "        self.decay = decay\n",
        "        self.iterations = 0\n",
        "        self.epsilon = epsilon\n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "\n",
        "    # Call once before any parameter updates\n",
        "    def pre_update_params(self):\n",
        "        if self.decay:\n",
        "            self.current_learning_rate = self.learning_rate * \\\n",
        "                                         (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "    # Update parameters\n",
        "    def update_params(self, layer):\n",
        "\n",
        "        # If layer does not contain cache arrays,\n",
        "        # create them filled with zeros\n",
        "        if not hasattr(layer, 'weight_cache'):\n",
        "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
        "            layer.weight_cache = np.zeros_like(layer.weights)\n",
        "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
        "            layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "        # Update momentum  with current gradients\n",
        "        layer.weight_momentums = self.beta_1 * \\\n",
        "                                 layer.weight_momentums + \\\n",
        "                                 (1 - self.beta_1) * layer.dweights\n",
        "        layer.bias_momentums = self.beta_1 * \\\n",
        "                               layer.bias_momentums + \\\n",
        "                               (1 - self.beta_1) * layer.dbiases\n",
        "        # Get corrected momentum\n",
        "        # self.iteration is 0 at first pass\n",
        "        # and we need to start with 1 here\n",
        "        weight_momentums_corrected = layer.weight_momentums / \\\n",
        "                                     (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        bias_momentums_corrected = layer.bias_momentums / \\\n",
        "                                   (1 - self.beta_1 ** (self.iterations + 1))\n",
        "        # Update cache with squared current gradients\n",
        "        layer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
        "                             (1 - self.beta_2) * layer.dweights ** 2\n",
        "        layer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
        "                           (1 - self.beta_2) * layer.dbiases ** 2\n",
        "        # Get corrected cache\n",
        "        weight_cache_corrected = layer.weight_cache / \\\n",
        "                                 (1 - self.beta_2 ** (self.iterations + 1))\n",
        "        bias_cache_corrected = layer.bias_cache / \\\n",
        "                               (1 - self.beta_2 ** (self.iterations + 1))\n",
        "\n",
        "        # Vanilla SGD parameter update + normalization\n",
        "        # with square rooted cache\n",
        "        layer.weights += -self.current_learning_rate * \\\n",
        "                         weight_momentums_corrected / \\\n",
        "                         (np.sqrt(weight_cache_corrected) +\n",
        "                          self.epsilon)\n",
        "        layer.biases += -self.current_learning_rate * \\\n",
        "                        bias_momentums_corrected / \\\n",
        "                        (np.sqrt(bias_cache_corrected) +\n",
        "                         self.epsilon)\n",
        "\n",
        "    # Call once after any parameter updates\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n",
        "\n",
        "# Common loss class\n",
        "class Loss:\n",
        "\n",
        "\n",
        "    # Regularization loss calculation\n",
        "    def regularization_loss(self, layer):\n",
        "\n",
        "        # 0 by default\n",
        "        regularization_loss = 0\n",
        "\n",
        "        # L1 regularization - weights\n",
        "        # calculate only when factor greater than 0\n",
        "        if layer.weight_regularizer_l1 > 0:\n",
        "            regularization_loss += layer.weight_regularizer_l1 * \\\n",
        "                                   np.sum(np.abs(layer.weights))\n",
        "\n",
        "        # L2 regularization - weights\n",
        "        if layer.weight_regularizer_l2 > 0:\n",
        "            regularization_loss += layer.weight_regularizer_l2 * \\\n",
        "                                   np.sum(layer.weights *\n",
        "                                          layer.weights)\n",
        "\n",
        "        # L1 regularization - biases\n",
        "        # calculate only when factor greater than 0\n",
        "        if layer.bias_regularizer_l1 > 0:\n",
        "            regularization_loss += layer.bias_regularizer_l1 * \\\n",
        "                                   np.sum(np.abs(layer.biases))\n",
        "\n",
        "        # L2 regularization - biases\n",
        "        if layer.bias_regularizer_l2 > 0:\n",
        "            regularization_loss += layer.bias_regularizer_l2 * \\\n",
        "                                   np.sum(layer.biases *\n",
        "                                          layer.biases)\n",
        "\n",
        "        return regularization_loss\n",
        "\n",
        "\n",
        "    # Set/remember trainable layers\n",
        "    def remember_trainable_layers(self, trainable_layers):\n",
        "        self.trainable_layers = trainable_layers\n",
        "\n",
        "    # Calculates the data and regularization losses\n",
        "    # given model output and ground truth values\n",
        "    def calculate(self, output, y, *, include_regularization=False):\n",
        "\n",
        "        # Calculate sample losses\n",
        "        sample_losses = self.forward(output, y)\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = np.mean(sample_losses)\n",
        "\n",
        "        # Return loss\n",
        "        return data_loss\n",
        "\n",
        "    # Calculates accumulated loss\n",
        "    def calculate_accumulated(self, *, include_regularization=False):\n",
        "\n",
        "        # Calculate mean loss\n",
        "        data_loss = self.accumulated_sum / self.accumulated_count\n",
        "\n",
        "        # If just data loss - return it\n",
        "        if not include_regularization:\n",
        "            return data_loss\n",
        "\n",
        "        # Return the data and regularization losses\n",
        "        return data_loss, self.regularization_loss()\n",
        "\n",
        "    # Reset variables for accumulated loss\n",
        "    def new_pass(self):\n",
        "        self.accumulated_sum = 0\n",
        "        self.accumulated_count = 0\n",
        "\n",
        "\n",
        "# Cross-entropy loss\n",
        "class Loss_CategoricalCrossentropy(Loss):\n",
        "\n",
        "        # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "\n",
        "        # Number of samples in a batch\n",
        "        samples = len(y_pred)\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Probabilities for target values -\n",
        "        # only if categorical labels\n",
        "        if len(y_true.shape) == 1:\n",
        "            correct_confidences = y_pred_clipped[\n",
        "                range(samples),\n",
        "                y_true\n",
        "            ]\n",
        "\n",
        "        # Mask values - only for one-hot encoded labels\n",
        "        elif len(y_true.shape) == 2:\n",
        "            correct_confidences = np.sum(\n",
        "                y_pred_clipped * y_true,\n",
        "                axis=1\n",
        "            )\n",
        "\n",
        "        # Losses\n",
        "        negative_log_likelihoods = -np.log(correct_confidences)\n",
        "        return negative_log_likelihoods\n",
        "\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of labels in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        labels = len(dvalues[0])\n",
        "\n",
        "        # If labels are sparse, turn them into one-hot vector\n",
        "        if len(y_true.shape) == 1:\n",
        "            y_true = np.eye(labels)[y_true]\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -y_true / dvalues\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Softmax classifier - combined Softmax activation\n",
        "# and cross-entropy loss for faster backward step\n",
        "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
        "\n",
        "    # Creates activation and loss function objects\n",
        "    def __init__(self):\n",
        "        self.activation = Activation_Softmax()\n",
        "        self.loss = Loss_CategoricalCrossentropy()\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs, y_true):\n",
        "        # Output layer's activation function\n",
        "        self.activation.forward(inputs)\n",
        "        # Set the output\n",
        "        self.output = self.activation.output\n",
        "        # Calculate and return loss value\n",
        "        return self.loss.calculate(self.output, y_true)\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "\n",
        "        # If labels are one-hot encoded,\n",
        "        # turn them into discrete values\n",
        "        if len(y_true.shape) == 2:\n",
        "            y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "        # Copy so we can safely modify\n",
        "        self.dinputs = dvalues.copy()\n",
        "        # Calculate gradient\n",
        "        self.dinputs[range(samples), y_true] -= 1\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "\n",
        "# Binary cross-entropy loss\n",
        "class Loss_BinaryCrossentropy(Loss):\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, y_pred, y_true):\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Calculate sample-wise loss\n",
        "        sample_losses = -(y_true * np.log(y_pred_clipped) +\n",
        "                          (1 - y_true) * np.log(1 - y_pred_clipped))\n",
        "        sample_losses = np.mean(sample_losses, axis=-1)\n",
        "\n",
        "        # Return losses\n",
        "        return sample_losses\n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues, y_true):\n",
        "        # Number of samples\n",
        "        samples = len(dvalues)\n",
        "        # Number of outputs in every sample\n",
        "        # We'll use the first sample to count them\n",
        "        outputs = len(dvalues[0])\n",
        "\n",
        "        # Clip data to prevent division by 0\n",
        "        # Clip both sides to not drag mean towards any value\n",
        "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
        "\n",
        "        # Calculate gradient\n",
        "        self.dinputs = -(y_true / clipped_dvalues -\n",
        "                         (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
        "        # Normalize gradient\n",
        "        self.dinputs = self.dinputs / samples\n",
        "\n",
        "# Common accuracy class\n",
        "class Accuracy:\n",
        "\n",
        "    # Calculates an accuracy\n",
        "    # given predictions and ground truth values\n",
        "    def calculate(self, predictions, y):\n",
        "\n",
        "        # Get comparison results\n",
        "        comparisons = self.compare(predictions, y)\n",
        "\n",
        "        # Calculate an accuracy\n",
        "        accuracy = np.mean(comparisons)\n",
        "\n",
        "        # Add accumulated sum of matching values and sample count\n",
        "        # Return accuracy\n",
        "        return accuracy\n",
        "\n",
        "    # Calculates accumulated accuracy\n",
        "    def calculate_accumulated(self):\n",
        "\n",
        "        # Calculate an accuracy\n",
        "        accuracy = self.accumulated_sum / self.accumulated_count\n",
        "\n",
        "        # Return the data and regularization losses\n",
        "        return accuracy\n",
        "\n",
        "    # Reset variables for accumulated accuracy\n",
        "    def new_pass(self):\n",
        "        self.accumulated_sum = 0\n",
        "        self.accumulated_count = 0\n",
        "\n",
        "\n",
        "# Accuracy calculation for classification model\n",
        "class Accuracy_Categorical(Accuracy):\n",
        "\n",
        "    def __init__(self, *, binary=False):\n",
        "        # Binary mode?\n",
        "        self.binary = binary\n",
        "\n",
        "    # No initialization is needed\n",
        "    def init(self, y):\n",
        "        pass\n",
        "\n",
        "    # Compares predictions to the ground truth values\n",
        "    def compare(self, predictions, y):\n",
        "        if not self.binary and len(y.shape) == 2:\n",
        "            y = np.argmax(y, axis=1)\n",
        "        return predictions == y\n",
        "\n",
        "\n",
        "# Accuracy calculation for regression model\n",
        "class Accuracy_Regression(Accuracy):\n",
        "\n",
        "    def __init__(self):\n",
        "        # Create precision property\n",
        "        self.precision = None\n",
        "\n",
        "    # Calculates precision value\n",
        "    # based on passed-in ground truth values\n",
        "    def init(self, y, reinit=False):\n",
        "        if self.precision is None or reinit:\n",
        "            self.precision = np.std(y) / 250\n",
        "\n",
        "    # Compares predictions to the ground truth values\n",
        "    def compare(self, predictions, y):\n",
        "        return np.absolute(predictions - y) < self.precision\n",
        "\n",
        "class model:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def predict(self, classes, samples):\n",
        "        self.classes = classes\n",
        "        self.samples = samples\n",
        "        self.X, self.y = spiral_data(samples=self.samples, classes=self.classes)\n",
        "        dense1.forward(self.X)\n",
        "        activation1.forward(dense1.output)\n",
        "        dense2.forward(activation1.output)\n",
        "        activation2.forward(dense2.output)\n",
        "        # Calculate the data loss\n",
        "        self.loss = loss_function.calculate(activation2.output, self.y)\n",
        "        self.predictions = (activation2.output > 0.5) * 1\n",
        "        self.accuracy = np.mean(self.predictions == self.y)\n",
        "        print(f'Accuracy: {self.accuracy}')\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA4GFMbIPUkI"
      },
      "source": [
        "# Old Dropout Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxoiO43tPbTa"
      },
      "source": [
        "class Layer_Dropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        # Store rate, we invert it as for example for dropout\n",
        "        # of 0.1 we need success rate of 0.9\n",
        "        self.rate = 1 - rate\n",
        "\n",
        "    # Forward pass\n",
        "    def forward(self, inputs):\n",
        "        # Save input values\n",
        "        self.inputs = inputs\n",
        "        # Generate and save scaled mask\n",
        "        self.binary_mask = np.random.binomial(1, self.rate,\n",
        "                                              size=inputs.shape) / self.rate\n",
        "        # Apply mask to output values\n",
        "        self.output = inputs * self.binary_mask\n",
        "       \n",
        "\n",
        "    # Backward pass\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "        #print(self.dinputs.shape)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_Og9ZrbKtV"
      },
      "source": [
        "# New Dropout Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXBWsHDIUSfh"
      },
      "source": [
        "class Layer_BinaryNSDropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        self.rate = 1 - rate\n",
        "        self.iterations = 0\n",
        "\n",
        "    def forward(self, inputs, val_inputs):\n",
        "        self.inputs = inputs\n",
        "        self.val_inputs = val_inputs\n",
        "        nummask = round(len(self.inputs[0]) * self.rate)\n",
        "        \n",
        "        #Averaging Values\n",
        "        self.meanarray1 = np.mean(inputs, axis=0)\n",
        "        self.meanarray2 = np.mean(val_inputs, axis=0)\n",
        "\n",
        "        if self.iterations != 0:\n",
        "            # Calculating value\n",
        "            self.difference = self.meanarray1 - self.meanarray2\n",
        "            ind = np.argpartition(self.difference, -nummask)[-nummask:]\n",
        "            mask = np.ones(self.meanarray1.shape, dtype=bool)\n",
        "            mask[ind] = False\n",
        "            self.difference[~mask] = 1\n",
        "            self.difference[mask] = 0. \n",
        "            self.binary_mask = self.difference / self.rate\n",
        "\n",
        "        else:\n",
        "            self.binary_mask = np.random.binomial(1, self.rate,\n",
        "                                                  size=inputs.shape) / self.rate\n",
        "        self.output = inputs * self.binary_mask\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiuCzwWxbRl0"
      },
      "source": [
        "class Layer_CatagoricalNSDropout:\n",
        "\n",
        "    # Init\n",
        "    def __init__(self, rate):\n",
        "        self.rate = rate\n",
        "        self.iterations = 0\n",
        "\n",
        "    def forward(self, X_test, y_test, X, y):        \n",
        "        if self.iterations != 0:\n",
        "          #Sorting data into classes\n",
        "          idx = np.argsort(y_test)\n",
        "          X_test_sorted = X_test[idx]\n",
        "          y_test_sorted = y_test[idx]\n",
        "\n",
        "          idx2 = np.argsort(y)\n",
        "          X_train_sorted = X[idx2]\n",
        "          y_train_sorted = y[idx2]\n",
        "\n",
        "          #Adding sorted data into dictionaries \n",
        "          sorted_x = {}\n",
        "          sorted_y = {}\n",
        "          for classes in range(len(set(y))):\n",
        "            sorted_x[\"class_{0}\".format(classes)] = X[y == classes]\n",
        "            sorted_y[\"label_{0}\".format(classes)] = y[y == classes]\n",
        "\n",
        "          sorted_x_test = {}\n",
        "          sorted_y_test = {}\n",
        "          for classes in range(len(set(y))):\n",
        "            sorted_x_test[\"class_{0}\".format(classes)] = X_test[y_test == classes]\n",
        "            sorted_y_test[\"label_{0}\".format(classes)] = y_test[y_test == classes]\n",
        "\n",
        "          #Averaging sorted data from each class then finding the difference between the averaged train and test inputs\n",
        "          differnce_classes = {}\n",
        "          for i, classes, test_classes in zip(range(len(set(y))), sorted_x, sorted_x_test):\n",
        "            differnce_classes[\"diff_{0}\".format(i)] = np.mean(sorted_x[classes], axis=0) - np.mean(sorted_x_test[classes], axis=0)\n",
        "\n",
        "          #Masking the data taking the high values(greatest difference between train and test) and setting their values to 0\n",
        "          self.diff_mask = {}\n",
        "          for i, classes, test_classes, diff in zip(range(len(set(y))), sorted_x, sorted_x_test, differnce_classes):\n",
        "            ind = np.argpartition(differnce_classes[diff], -round(len(X[0]) * self.rate))[-round(len(X[0]) * self.rate):]\n",
        "            mask = np.ones(np.mean(sorted_x[classes],axis=0).shape, dtype=bool)\n",
        "            mask[ind] = False\n",
        "            differnce_classes[diff][~mask] = 0.\n",
        "            differnce_classes[diff][mask] = 1\n",
        "            self.diff_mask[\"mask_{0}\".format(i)] = differnce_classes[diff]\n",
        "\n",
        "          #Goes through each input values and applies the apprioprite mask based on what the true output should be.\n",
        "          binary_mask = np.empty(shape=X.shape)\n",
        "          for i, input, label in zip(range(len(X)), X, y):\n",
        "            for true, diff in enumerate(self.diff_mask):\n",
        "              if label == true:\n",
        "                self.binary_mask[i] = self.diff_mask[diff]\n",
        "        else:\n",
        "          self.binary_mask = np.random.binomial(1, (1-self.rate), size=X.shape)\n",
        "        \n",
        "        self.output = (self.binary_mask/(1-self.rate)) * X\n",
        "    def backward(self, dvalues):\n",
        "        # Gradient on values\n",
        "        self.dinputs = dvalues * self.binary_mask\n",
        "\n",
        "    def infrence(self, input, label):\n",
        "        self.input = input\n",
        "        self.label = label\n",
        "        idx = np.argsort(self.label)\n",
        "        input_sorted = input[idx]\n",
        "        label_sorted = label[idx]\n",
        "        self.infrence_binary_mask = np.empty(shape=self.input.shape)\n",
        "        for i, (input, label) in enumerate(zip(self.input, self.label)):\n",
        "          #for true, diff in zip(range(len(set(self.label))),self.diff_mask):\n",
        "          for true, diff in enumerate(self.diff_mask):\n",
        "            if label == true:\n",
        "              self.infrence_binary_mask[i] = self.diff_mask[diff]\n",
        "\n",
        "        self.output = self.infrence_binary_mask * self.input\n",
        "\n",
        "    def post_update_params(self):\n",
        "        self.iterations += 1\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRB57nFublm3"
      },
      "source": [
        "Initializing Caches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kyAX0txV-cF"
      },
      "source": [
        "loss_cache = []\n",
        "val_loss_cache = []\n",
        "acc_cache = []\n",
        "val_acc_cache = []\n",
        "lr_cache = []\n",
        "epoch_cache = []\n",
        "test_acc_cache = []\n",
        "test_loss_cache = []\n",
        "\n",
        "max_val_accuracyint = 0"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_7VWnIlF8yx"
      },
      "source": [
        "Initializing Summary List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtnu5VToGAq0"
      },
      "source": [
        "summary = []"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Eu0pm-WjKI"
      },
      "source": [
        "# Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-24YuBKre0f"
      },
      "source": [
        "Vizulizing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kUOJ9avrho8",
        "outputId": "f6a0427b-22af-455a-bc07-2dd11aee093b"
      },
      "source": [
        "#(X, y), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "# load dataset\n",
        "(X, y), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "# Label index to label name relation\n",
        "number_mnist_labels = {\n",
        "    0: '0',\n",
        "    1: '1',\n",
        "    2: '2',\n",
        "    3: '3',\n",
        "    4: '4',\n",
        "    5: '5',\n",
        "    6: '6',\n",
        "    7: '7',\n",
        "    8: '8',\n",
        "    9: '9'\n",
        "}\n",
        "\n",
        "# Shuffle the training dataset\n",
        "keys = np.array(range(X.shape[0]))\n",
        "np.random.shuffle(keys)\n",
        "X = X[keys]\n",
        "y = y[keys]\n",
        "\n",
        "\n",
        "X = X[:8000,:,:]\n",
        "X_test = X_test[:1600,:,:]\n",
        "y = y[:8000]\n",
        "y_test  = y_test[:1600]\n",
        "\n",
        "\n",
        "\n",
        "# Scale and reshape samples\n",
        "X = (X.reshape(X.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
        "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 784)\n",
            "(8000,)\n",
            "(1600, 784)\n",
            "(1600,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_nW7mqGTnem"
      },
      "source": [
        "Sorting Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtvA9y81TpGf",
        "outputId": "a40a32b4-d9ad-4a23-bf53-cad9ce91a25c"
      },
      "source": [
        "idx = np.argsort(y)\n",
        "X_sorted = X[idx]\n",
        "y_sorted = y[idx]\n",
        "\n",
        "sorted_x = {}\n",
        "sorted_y = {}\n",
        "for classes in range(len(set(y))):\n",
        "  sorted_x[\"X_{0}\".format(classes)] = X[y == classes]\n",
        "  sorted_y[\"y_{0}\".format(classes)] = y[y == classes]\n",
        "\n",
        "\n",
        "\n",
        "for sorted_lists in sorted_x:\n",
        "  print(f'Number of Samples for {sorted_lists}: {sorted_x[sorted_lists].shape[0]}')\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples for X_0: 818\n",
            "Number of Samples for X_1: 866\n",
            "Number of Samples for X_2: 808\n",
            "Number of Samples for X_3: 774\n",
            "Number of Samples for X_4: 768\n",
            "Number of Samples for X_5: 702\n",
            "Number of Samples for X_6: 735\n",
            "Number of Samples for X_7: 891\n",
            "Number of Samples for X_8: 820\n",
            "Number of Samples for X_9: 818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpaNaUO3kP2G"
      },
      "source": [
        "Sorting Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBLFeGAUkSOs",
        "outputId": "999c279c-11ac-442f-d5e9-b99f0683cd7a"
      },
      "source": [
        "idx = np.argsort(y_test)\n",
        "X_test_sorted = X_test[idx]\n",
        "y_test_sorted = y_test[idx]\n",
        "\n",
        "class_list = []\n",
        "\n",
        "sorted_x_test = {}\n",
        "sorted_y_test = {}\n",
        "for classes in range(len(set(y))):\n",
        "  sorted_x_test[\"X_test_{0}\".format(classes)] = X_test[y_test == classes]\n",
        "  sorted_y_test[\"y_test_{0}\".format(classes)] = y_test[y_test == classes]\n",
        "\n",
        "\n",
        "for sorted_lists in sorted_x_test:\n",
        "  print(f'Number of Samples for {sorted_lists}: {sorted_x_test[sorted_lists].shape[0]}')\n",
        "  class_list.append(sorted_x_test[sorted_lists].shape[0])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Samples for X_test_0: 137\n",
            "Number of Samples for X_test_1: 185\n",
            "Number of Samples for X_test_2: 180\n",
            "Number of Samples for X_test_3: 162\n",
            "Number of Samples for X_test_4: 181\n",
            "Number of Samples for X_test_5: 142\n",
            "Number of Samples for X_test_6: 139\n",
            "Number of Samples for X_test_7: 165\n",
            "Number of Samples for X_test_8: 154\n",
            "Number of Samples for X_test_9: 155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hbnq4TJp1cl",
        "outputId": "f1aeeb8c-26e6-4ea7-b5e8-fbab671137ef"
      },
      "source": [
        "print(f'Found {X.shape[0]} images belonging to {len(set(y))} unique classes')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 10 unique classes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd_dSHDNW1Rn"
      },
      "source": [
        "# Initializing Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aly5fwUCW_4l"
      },
      "source": [
        "# Create Dense layer with 2 input features and 64 output values\n",
        "dense1 = Layer_Dense(X.shape[1], 128, weight_regularizer_l2=5e-4,\n",
        "                     bias_regularizer_l2=5e-4)\n",
        "\n",
        "activation1 = Activation_ReLU()\n",
        "\n",
        "dropout1 = Layer_CatagoricalNSDropout(0.2)\n",
        "\n",
        "dense2 = Layer_Dense(128, 128)\n",
        "\n",
        "activation2 = Activation_ReLU()\n",
        "\n",
        "dense3 = Layer_Dense(128,128)\n",
        "\n",
        "activation3 = Activation_ReLU()\n",
        "\n",
        "dense4 = Layer_Dense(128,len(set(y)))\n",
        "\n",
        "activation4 = Activation_Softmax()\n",
        "\n",
        "\n",
        "loss_function = Loss_CategoricalCrossentropy()\n",
        "\n",
        "softmax_classifier_output = \\\n",
        "                Activation_Softmax_Loss_CategoricalCrossentropy()\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = Optimizer_Adam(decay=5e-7,learning_rate=0.005)\n",
        "#optimizer = Optimizer_SGD(learning_rate=0.01)\n",
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(y)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xmbxDuwXIBk"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14yHOjq9XLee",
        "outputId": "b3e50f1a-1ee9-442d-b65a-13fad3d470d5"
      },
      "source": [
        "epochs = 250\n",
        "for epoch in range(epochs + 1):\n",
        "\n",
        "    dense1.forward(X)\n",
        "\n",
        "    activation1.forward(dense1.output)\n",
        "\n",
        "    if epoch != 0:\n",
        "      cached_val_inputs = cached_val_inputs\n",
        "      cached_train_inputs = activation1.output\n",
        "    else:\n",
        "      cached_val_inputs = np.random.random(size=128) #Never used just needed to pass to dropout\n",
        "      cached_train_inputs = activation1.output\n",
        "\n",
        "\n",
        "    dropout1.forward(X=activation1.output, y=y, X_test=cached_val_inputs, y_test=y_test)\n",
        "\n",
        "    dense2.forward(dropout1.output)\n",
        "\n",
        "    activation2.forward(dense2.output)\n",
        "\n",
        "    dense3.forward(activation2.output)\n",
        "\n",
        "    activation3.forward(dense3.output)\n",
        "\n",
        "    dense4.forward(activation3.output)\n",
        "\n",
        "    activation4.forward(dense4.output)\n",
        "\n",
        "    # Calculate the data loss\n",
        "    data_loss = loss_function.calculate(activation4.output, y)\n",
        "    regularization_loss = \\\n",
        "      loss_function.regularization_loss(dense1) + \\\n",
        "      loss_function.regularization_loss(dense2) + \\\n",
        "      loss_function.regularization_loss(dense3) + \\\n",
        "      loss_function.regularization_loss(dense4) \n",
        "    loss = data_loss + regularization_loss\n",
        "    \n",
        "    #Accuracy\n",
        "    predictions = activation4.predictions(activation4.output)\n",
        "    train_accuracy = accuracy.calculate(predictions, y)\n",
        "\n",
        "    # Backward pass\n",
        "    softmax_classifier_output.backward(activation4.output, y)\n",
        "    activation4.backward(softmax_classifier_output.dinputs)\n",
        "    dense4.backward(activation4.dinputs)\n",
        "    activation3.backward(dense4.dinputs)\n",
        "    dense3.backward(activation3.dinputs)\n",
        "    activation2.backward(dense3.dinputs)\n",
        "    dense2.backward(activation2.dinputs)\n",
        "    dropout1.backward(dense2.dinputs)\n",
        "    activation1.backward(dropout1.dinputs)\n",
        "    dense1.backward(activation1.dinputs)\n",
        "    \n",
        "    # Update weights and biases\n",
        "    optimizer.pre_update_params()\n",
        "    optimizer.update_params(dense1)\n",
        "    optimizer.update_params(dense2)\n",
        "    optimizer.update_params(dense3)\n",
        "    optimizer.update_params(dense4)\n",
        "    optimizer.post_update_params()\n",
        "    dropout1.post_update_params()\n",
        "\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    dense1.forward(X_test)\n",
        "    activation1.forward(dense1.output)\n",
        "    \n",
        "    if epoch == 0:\n",
        "      dense2.forward(activation1.output)\n",
        "    else:\n",
        "      dropout1.infrence(activation1.output,y_test)\n",
        "\n",
        "      dense2.forward(dropout1.output)\n",
        "    \n",
        "    dense1_outputs = dense1.output\n",
        "    meanarray = np.mean(dense1.output, axis=0)\n",
        "    cached_val_inputs = activation1.output\n",
        " \n",
        "    trainout = meanarray\n",
        "    activation2.forward(dense2.output)\n",
        "\n",
        "    dense3.forward(activation2.output)\n",
        "    activation3.forward(dense3.output)\n",
        "    dense4.forward(activation3.output)\n",
        "    activation4.forward(dense4.output)\n",
        "    # Calculate the data loss\n",
        "    valloss = loss_function.calculate(activation4.output, y_test)\n",
        "    predictions = activation4.predictions(activation4.output)\n",
        "    valaccuracy = accuracy.calculate(predictions, y_test)\n",
        "\n",
        "    #Updating List\n",
        "    loss_cache.append(loss)\n",
        "    val_loss_cache.append(valloss)\n",
        "    acc_cache.append(train_accuracy)\n",
        "    val_acc_cache.append(valaccuracy)\n",
        "    lr_cache.append(optimizer.current_learning_rate)\n",
        "    epoch_cache.append(epoch)\n",
        "    \n",
        "\n",
        "    #Summary Items\n",
        "    if valaccuracy >= .8 and len(summary) == 0:\n",
        "        nintypercent = f'Model hit 80% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .85 and len(summary) == 1:\n",
        "        nintypercent = f'Model hit 85% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .9 and len(summary) == 2:\n",
        "        nintypercent = f'Model hit 90% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .95 and len(summary) == 3:\n",
        "        nintypercent = f'Model hit 95% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if valaccuracy >= .975 and len(summary) == 4:\n",
        "        nintypercent = f'Model hit 97.5% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)  \n",
        "    if valaccuracy >= 1 and len(summary) == 5:\n",
        "        nintypercent = f'Model hit 100% validation accuracy in {epoch} epochs'\n",
        "        summary.append(nintypercent)\n",
        "    if epoch == epochs:\n",
        "      if valaccuracy > max_val_accuracyint:\n",
        "        max_val_accuracyint = valaccuracy\n",
        "        max_val_accuracy = f'Max accuracy was {valaccuracy * 100}% at epoch {epoch}.'\n",
        "        summary.append(max_val_accuracy)\n",
        "      else:\n",
        "        summary.append(max_val_accuracy)\n",
        "    else:\n",
        "      if valaccuracy > max_val_accuracyint:\n",
        "        max_val_accuracyint = valaccuracy\n",
        "        max_val_accuracy = f'Max accuracy was {valaccuracy * 100}% at epoch {epoch}.'     \n",
        "    \n",
        "    if not epoch % 1:\n",
        "        print(f'epoch: {epoch}, ' +\n",
        "              f'acc: {train_accuracy:.3f}, ' +\n",
        "              f'loss: {loss:.3f} (' +\n",
        "              f'data_loss: {data_loss:.3f}, ' +\n",
        "              f'reg_loss: {regularization_loss:.3f}), ' +\n",
        "              f'lr: {optimizer.current_learning_rate:.9f} ' +\n",
        "              f'validation, acc: {valaccuracy:.3f}, loss: {valloss:.3f} ')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0, acc: 0.096, loss: 2.308 (data_loss: 2.303, reg_loss: 0.005), lr: 0.005000000 validation, acc: 0.104, loss: 2.302 \n",
            "epoch: 1, acc: 0.111, loss: 2.304 (data_loss: 2.302, reg_loss: 0.002), lr: 0.004999998 validation, acc: 0.103, loss: 2.299 \n",
            "epoch: 2, acc: 0.111, loss: 2.300 (data_loss: 2.299, reg_loss: 0.001), lr: 0.004999995 validation, acc: 0.103, loss: 2.275 \n",
            "epoch: 3, acc: 0.111, loss: 2.274 (data_loss: 2.274, reg_loss: 0.001), lr: 0.004999993 validation, acc: 0.103, loss: 2.203 \n",
            "epoch: 4, acc: 0.111, loss: 2.220 (data_loss: 2.219, reg_loss: 0.001), lr: 0.004999990 validation, acc: 0.103, loss: 2.131 \n",
            "epoch: 5, acc: 0.111, loss: 2.136 (data_loss: 2.135, reg_loss: 0.002), lr: 0.004999988 validation, acc: 0.339, loss: 2.118 \n",
            "epoch: 6, acc: 0.363, loss: 2.107 (data_loss: 2.104, reg_loss: 0.003), lr: 0.004999985 validation, acc: 0.346, loss: 1.995 \n",
            "epoch: 7, acc: 0.301, loss: 2.082 (data_loss: 2.078, reg_loss: 0.003), lr: 0.004999983 validation, acc: 0.319, loss: 1.903 \n",
            "epoch: 8, acc: 0.299, loss: 1.922 (data_loss: 1.918, reg_loss: 0.004), lr: 0.004999980 validation, acc: 0.296, loss: 1.903 \n",
            "epoch: 9, acc: 0.298, loss: 1.913 (data_loss: 1.908, reg_loss: 0.005), lr: 0.004999978 validation, acc: 0.301, loss: 1.745 \n",
            "epoch: 10, acc: 0.311, loss: 1.729 (data_loss: 1.724, reg_loss: 0.006), lr: 0.004999975 validation, acc: 0.433, loss: 1.608 \n",
            "epoch: 11, acc: 0.395, loss: 1.624 (data_loss: 1.618, reg_loss: 0.006), lr: 0.004999973 validation, acc: 0.279, loss: 1.612 \n",
            "epoch: 12, acc: 0.368, loss: 1.627 (data_loss: 1.620, reg_loss: 0.007), lr: 0.004999970 validation, acc: 0.519, loss: 1.523 \n",
            "epoch: 13, acc: 0.416, loss: 1.530 (data_loss: 1.522, reg_loss: 0.008), lr: 0.004999968 validation, acc: 0.427, loss: 1.451 \n",
            "epoch: 14, acc: 0.381, loss: 1.538 (data_loss: 1.529, reg_loss: 0.008), lr: 0.004999965 validation, acc: 0.426, loss: 1.305 \n",
            "epoch: 15, acc: 0.423, loss: 1.511 (data_loss: 1.502, reg_loss: 0.009), lr: 0.004999963 validation, acc: 0.603, loss: 1.197 \n",
            "epoch: 16, acc: 0.597, loss: 1.171 (data_loss: 1.162, reg_loss: 0.010), lr: 0.004999960 validation, acc: 0.420, loss: 1.232 \n",
            "epoch: 17, acc: 0.392, loss: 1.377 (data_loss: 1.367, reg_loss: 0.010), lr: 0.004999958 validation, acc: 0.636, loss: 1.129 \n",
            "epoch: 18, acc: 0.624, loss: 1.111 (data_loss: 1.100, reg_loss: 0.011), lr: 0.004999955 validation, acc: 0.656, loss: 1.135 \n",
            "epoch: 19, acc: 0.662, loss: 1.127 (data_loss: 1.115, reg_loss: 0.011), lr: 0.004999953 validation, acc: 0.704, loss: 1.000 \n",
            "epoch: 20, acc: 0.684, loss: 1.030 (data_loss: 1.018, reg_loss: 0.012), lr: 0.004999950 validation, acc: 0.673, loss: 0.910 \n",
            "epoch: 21, acc: 0.690, loss: 0.921 (data_loss: 0.908, reg_loss: 0.013), lr: 0.004999948 validation, acc: 0.703, loss: 0.844 \n",
            "epoch: 22, acc: 0.743, loss: 0.777 (data_loss: 0.764, reg_loss: 0.013), lr: 0.004999945 validation, acc: 0.821, loss: 0.691 \n",
            "epoch: 23, acc: 0.832, loss: 0.625 (data_loss: 0.611, reg_loss: 0.014), lr: 0.004999943 validation, acc: 0.875, loss: 0.567 \n",
            "epoch: 24, acc: 0.833, loss: 0.570 (data_loss: 0.555, reg_loss: 0.015), lr: 0.004999940 validation, acc: 0.928, loss: 0.514 \n",
            "epoch: 25, acc: 0.757, loss: 0.647 (data_loss: 0.631, reg_loss: 0.015), lr: 0.004999938 validation, acc: 0.774, loss: 0.662 \n",
            "epoch: 26, acc: 0.723, loss: 0.828 (data_loss: 0.813, reg_loss: 0.016), lr: 0.004999935 validation, acc: 0.793, loss: 0.566 \n",
            "epoch: 27, acc: 0.758, loss: 0.786 (data_loss: 0.770, reg_loss: 0.017), lr: 0.004999933 validation, acc: 0.770, loss: 0.715 \n",
            "epoch: 28, acc: 0.717, loss: 0.968 (data_loss: 0.951, reg_loss: 0.017), lr: 0.004999930 validation, acc: 0.821, loss: 0.750 \n",
            "epoch: 29, acc: 0.733, loss: 1.473 (data_loss: 1.455, reg_loss: 0.018), lr: 0.004999928 validation, acc: 0.706, loss: 1.110 \n",
            "epoch: 30, acc: 0.660, loss: 1.582 (data_loss: 1.563, reg_loss: 0.018), lr: 0.004999925 validation, acc: 0.748, loss: 1.598 \n",
            "epoch: 31, acc: 0.748, loss: 1.983 (data_loss: 1.964, reg_loss: 0.019), lr: 0.004999923 validation, acc: 0.745, loss: 1.350 \n",
            "epoch: 32, acc: 0.746, loss: 2.379 (data_loss: 2.359, reg_loss: 0.019), lr: 0.004999920 validation, acc: 0.686, loss: 2.106 \n",
            "epoch: 33, acc: 0.674, loss: 2.505 (data_loss: 2.485, reg_loss: 0.020), lr: 0.004999918 validation, acc: 0.787, loss: 2.091 \n",
            "epoch: 34, acc: 0.750, loss: 2.397 (data_loss: 2.377, reg_loss: 0.020), lr: 0.004999915 validation, acc: 0.690, loss: 1.950 \n",
            "epoch: 35, acc: 0.648, loss: 2.286 (data_loss: 2.266, reg_loss: 0.021), lr: 0.004999913 validation, acc: 0.674, loss: 1.634 \n",
            "epoch: 36, acc: 0.702, loss: 1.815 (data_loss: 1.794, reg_loss: 0.021), lr: 0.004999910 validation, acc: 0.734, loss: 1.802 \n",
            "epoch: 37, acc: 0.714, loss: 1.883 (data_loss: 1.861, reg_loss: 0.021), lr: 0.004999908 validation, acc: 0.720, loss: 1.800 \n",
            "epoch: 38, acc: 0.734, loss: 1.972 (data_loss: 1.950, reg_loss: 0.022), lr: 0.004999905 validation, acc: 0.709, loss: 1.774 \n",
            "epoch: 39, acc: 0.700, loss: 2.030 (data_loss: 2.008, reg_loss: 0.022), lr: 0.004999903 validation, acc: 0.752, loss: 1.451 \n",
            "epoch: 40, acc: 0.627, loss: 1.659 (data_loss: 1.637, reg_loss: 0.022), lr: 0.004999900 validation, acc: 0.657, loss: 1.312 \n",
            "epoch: 41, acc: 0.665, loss: 1.421 (data_loss: 1.398, reg_loss: 0.023), lr: 0.004999898 validation, acc: 0.684, loss: 1.115 \n",
            "epoch: 42, acc: 0.674, loss: 1.093 (data_loss: 1.070, reg_loss: 0.023), lr: 0.004999895 validation, acc: 0.662, loss: 1.079 \n",
            "epoch: 43, acc: 0.617, loss: 1.457 (data_loss: 1.434, reg_loss: 0.023), lr: 0.004999893 validation, acc: 0.817, loss: 1.061 \n",
            "epoch: 44, acc: 0.735, loss: 1.303 (data_loss: 1.280, reg_loss: 0.023), lr: 0.004999890 validation, acc: 0.642, loss: 1.433 \n",
            "epoch: 45, acc: 0.652, loss: 1.526 (data_loss: 1.502, reg_loss: 0.024), lr: 0.004999888 validation, acc: 0.729, loss: 1.433 \n",
            "epoch: 46, acc: 0.743, loss: 1.473 (data_loss: 1.449, reg_loss: 0.024), lr: 0.004999885 validation, acc: 0.703, loss: 1.421 \n",
            "epoch: 47, acc: 0.700, loss: 1.461 (data_loss: 1.437, reg_loss: 0.024), lr: 0.004999883 validation, acc: 0.643, loss: 1.379 \n",
            "epoch: 48, acc: 0.574, loss: 1.830 (data_loss: 1.806, reg_loss: 0.025), lr: 0.004999880 validation, acc: 0.604, loss: 1.532 \n",
            "epoch: 49, acc: 0.624, loss: 1.732 (data_loss: 1.707, reg_loss: 0.025), lr: 0.004999878 validation, acc: 0.665, loss: 1.275 \n",
            "epoch: 50, acc: 0.660, loss: 1.452 (data_loss: 1.427, reg_loss: 0.025), lr: 0.004999875 validation, acc: 0.651, loss: 1.068 \n",
            "epoch: 51, acc: 0.656, loss: 1.393 (data_loss: 1.367, reg_loss: 0.025), lr: 0.004999873 validation, acc: 0.658, loss: 1.275 \n",
            "epoch: 52, acc: 0.663, loss: 1.433 (data_loss: 1.408, reg_loss: 0.025), lr: 0.004999870 validation, acc: 0.677, loss: 1.173 \n",
            "epoch: 53, acc: 0.679, loss: 1.183 (data_loss: 1.158, reg_loss: 0.026), lr: 0.004999868 validation, acc: 0.693, loss: 0.891 \n",
            "epoch: 54, acc: 0.693, loss: 0.985 (data_loss: 0.959, reg_loss: 0.026), lr: 0.004999865 validation, acc: 0.716, loss: 0.845 \n",
            "epoch: 55, acc: 0.710, loss: 1.270 (data_loss: 1.245, reg_loss: 0.026), lr: 0.004999863 validation, acc: 0.769, loss: 1.054 \n",
            "epoch: 56, acc: 0.754, loss: 1.163 (data_loss: 1.137, reg_loss: 0.026), lr: 0.004999860 validation, acc: 0.776, loss: 0.940 \n",
            "epoch: 57, acc: 0.758, loss: 1.257 (data_loss: 1.231, reg_loss: 0.026), lr: 0.004999858 validation, acc: 0.778, loss: 1.010 \n",
            "epoch: 58, acc: 0.763, loss: 1.160 (data_loss: 1.134, reg_loss: 0.026), lr: 0.004999855 validation, acc: 0.792, loss: 0.942 \n",
            "epoch: 59, acc: 0.745, loss: 1.481 (data_loss: 1.455, reg_loss: 0.026), lr: 0.004999853 validation, acc: 0.767, loss: 1.202 \n",
            "epoch: 60, acc: 0.770, loss: 1.396 (data_loss: 1.370, reg_loss: 0.026), lr: 0.004999850 validation, acc: 0.787, loss: 1.123 \n",
            "epoch: 61, acc: 0.766, loss: 1.382 (data_loss: 1.356, reg_loss: 0.026), lr: 0.004999848 validation, acc: 0.782, loss: 1.100 \n",
            "epoch: 62, acc: 0.772, loss: 1.459 (data_loss: 1.433, reg_loss: 0.026), lr: 0.004999845 validation, acc: 0.787, loss: 1.171 \n",
            "epoch: 63, acc: 0.775, loss: 1.416 (data_loss: 1.390, reg_loss: 0.026), lr: 0.004999843 validation, acc: 0.792, loss: 1.130 \n",
            "epoch: 64, acc: 0.782, loss: 1.086 (data_loss: 1.061, reg_loss: 0.025), lr: 0.004999840 validation, acc: 0.797, loss: 0.878 \n",
            "epoch: 65, acc: 0.785, loss: 1.045 (data_loss: 1.020, reg_loss: 0.025), lr: 0.004999838 validation, acc: 0.799, loss: 0.854 \n",
            "epoch: 66, acc: 0.783, loss: 1.016 (data_loss: 0.991, reg_loss: 0.025), lr: 0.004999835 validation, acc: 0.800, loss: 0.809 \n",
            "epoch: 67, acc: 0.786, loss: 0.970 (data_loss: 0.946, reg_loss: 0.025), lr: 0.004999833 validation, acc: 0.803, loss: 0.769 \n",
            "epoch: 68, acc: 0.789, loss: 1.144 (data_loss: 1.119, reg_loss: 0.025), lr: 0.004999830 validation, acc: 0.803, loss: 0.919 \n",
            "epoch: 69, acc: 0.792, loss: 1.114 (data_loss: 1.089, reg_loss: 0.025), lr: 0.004999828 validation, acc: 0.806, loss: 0.890 \n",
            "epoch: 70, acc: 0.729, loss: 1.201 (data_loss: 1.177, reg_loss: 0.024), lr: 0.004999825 validation, acc: 0.792, loss: 1.133 \n",
            "epoch: 71, acc: 0.759, loss: 1.313 (data_loss: 1.289, reg_loss: 0.024), lr: 0.004999823 validation, acc: 0.726, loss: 1.456 \n",
            "epoch: 72, acc: 0.724, loss: 1.796 (data_loss: 1.772, reg_loss: 0.024), lr: 0.004999820 validation, acc: 0.796, loss: 1.149 \n",
            "epoch: 73, acc: 0.767, loss: 1.372 (data_loss: 1.348, reg_loss: 0.024), lr: 0.004999818 validation, acc: 0.758, loss: 1.048 \n",
            "epoch: 74, acc: 0.648, loss: 1.472 (data_loss: 1.448, reg_loss: 0.023), lr: 0.004999815 validation, acc: 0.752, loss: 1.123 \n",
            "epoch: 75, acc: 0.747, loss: 1.039 (data_loss: 1.016, reg_loss: 0.023), lr: 0.004999813 validation, acc: 0.760, loss: 1.011 \n",
            "epoch: 76, acc: 0.715, loss: 1.216 (data_loss: 1.193, reg_loss: 0.023), lr: 0.004999810 validation, acc: 0.799, loss: 0.804 \n",
            "epoch: 77, acc: 0.762, loss: 0.979 (data_loss: 0.956, reg_loss: 0.023), lr: 0.004999808 validation, acc: 0.772, loss: 0.784 \n",
            "epoch: 78, acc: 0.760, loss: 0.846 (data_loss: 0.824, reg_loss: 0.023), lr: 0.004999805 validation, acc: 0.749, loss: 0.765 \n",
            "epoch: 79, acc: 0.688, loss: 0.881 (data_loss: 0.859, reg_loss: 0.023), lr: 0.004999803 validation, acc: 0.766, loss: 0.747 \n",
            "epoch: 80, acc: 0.797, loss: 0.721 (data_loss: 0.699, reg_loss: 0.022), lr: 0.004999800 validation, acc: 0.868, loss: 0.677 \n",
            "epoch: 81, acc: 0.860, loss: 0.655 (data_loss: 0.633, reg_loss: 0.022), lr: 0.004999798 validation, acc: 0.880, loss: 0.651 \n",
            "epoch: 82, acc: 0.783, loss: 0.755 (data_loss: 0.733, reg_loss: 0.022), lr: 0.004999795 validation, acc: 0.883, loss: 0.653 \n",
            "epoch: 83, acc: 0.878, loss: 0.604 (data_loss: 0.581, reg_loss: 0.022), lr: 0.004999793 validation, acc: 0.864, loss: 0.585 \n",
            "epoch: 84, acc: 0.857, loss: 0.577 (data_loss: 0.555, reg_loss: 0.022), lr: 0.004999790 validation, acc: 0.876, loss: 0.503 \n",
            "epoch: 85, acc: 0.874, loss: 0.526 (data_loss: 0.504, reg_loss: 0.022), lr: 0.004999788 validation, acc: 0.884, loss: 0.456 \n",
            "epoch: 86, acc: 0.880, loss: 0.538 (data_loss: 0.515, reg_loss: 0.022), lr: 0.004999785 validation, acc: 0.887, loss: 0.515 \n",
            "epoch: 87, acc: 0.876, loss: 0.535 (data_loss: 0.513, reg_loss: 0.023), lr: 0.004999783 validation, acc: 0.888, loss: 0.442 \n",
            "epoch: 88, acc: 0.872, loss: 0.469 (data_loss: 0.446, reg_loss: 0.023), lr: 0.004999780 validation, acc: 0.886, loss: 0.368 \n",
            "epoch: 89, acc: 0.877, loss: 0.370 (data_loss: 0.347, reg_loss: 0.023), lr: 0.004999778 validation, acc: 0.943, loss: 0.316 \n",
            "epoch: 90, acc: 0.942, loss: 0.296 (data_loss: 0.273, reg_loss: 0.023), lr: 0.004999775 validation, acc: 0.961, loss: 0.242 \n",
            "epoch: 91, acc: 0.954, loss: 0.244 (data_loss: 0.221, reg_loss: 0.023), lr: 0.004999773 validation, acc: 0.980, loss: 0.182 \n",
            "epoch: 92, acc: 0.982, loss: 0.184 (data_loss: 0.160, reg_loss: 0.023), lr: 0.004999770 validation, acc: 0.991, loss: 0.156 \n",
            "epoch: 93, acc: 0.950, loss: 0.262 (data_loss: 0.239, reg_loss: 0.023), lr: 0.004999768 validation, acc: 0.967, loss: 0.223 \n",
            "epoch: 94, acc: 0.973, loss: 0.191 (data_loss: 0.167, reg_loss: 0.024), lr: 0.004999765 validation, acc: 0.979, loss: 0.161 \n",
            "epoch: 95, acc: 0.983, loss: 0.135 (data_loss: 0.112, reg_loss: 0.024), lr: 0.004999763 validation, acc: 0.989, loss: 0.115 \n",
            "epoch: 96, acc: 0.987, loss: 0.108 (data_loss: 0.084, reg_loss: 0.024), lr: 0.004999760 validation, acc: 0.988, loss: 0.106 \n",
            "epoch: 97, acc: 0.962, loss: 0.177 (data_loss: 0.154, reg_loss: 0.024), lr: 0.004999758 validation, acc: 0.988, loss: 0.120 \n",
            "epoch: 98, acc: 0.955, loss: 0.180 (data_loss: 0.156, reg_loss: 0.024), lr: 0.004999755 validation, acc: 0.966, loss: 0.153 \n",
            "epoch: 99, acc: 0.875, loss: 0.915 (data_loss: 0.891, reg_loss: 0.024), lr: 0.004999753 validation, acc: 0.869, loss: 0.889 \n",
            "epoch: 100, acc: 0.877, loss: 0.949 (data_loss: 0.925, reg_loss: 0.024), lr: 0.004999750 validation, acc: 0.876, loss: 0.930 \n",
            "epoch: 101, acc: 0.613, loss: 1.618 (data_loss: 1.594, reg_loss: 0.024), lr: 0.004999748 validation, acc: 0.771, loss: 1.251 \n",
            "epoch: 102, acc: 0.677, loss: 1.976 (data_loss: 1.952, reg_loss: 0.024), lr: 0.004999745 validation, acc: 0.676, loss: 1.912 \n",
            "epoch: 103, acc: 0.697, loss: 2.442 (data_loss: 2.418, reg_loss: 0.024), lr: 0.004999743 validation, acc: 0.684, loss: 2.369 \n",
            "epoch: 104, acc: 0.650, loss: 3.031 (data_loss: 3.007, reg_loss: 0.024), lr: 0.004999740 validation, acc: 0.680, loss: 2.688 \n",
            "epoch: 105, acc: 0.595, loss: 3.246 (data_loss: 3.223, reg_loss: 0.024), lr: 0.004999738 validation, acc: 0.594, loss: 2.851 \n",
            "epoch: 106, acc: 0.617, loss: 3.264 (data_loss: 3.241, reg_loss: 0.024), lr: 0.004999735 validation, acc: 0.577, loss: 2.744 \n",
            "epoch: 107, acc: 0.607, loss: 3.050 (data_loss: 3.026, reg_loss: 0.024), lr: 0.004999733 validation, acc: 0.620, loss: 2.612 \n",
            "epoch: 108, acc: 0.668, loss: 2.776 (data_loss: 2.752, reg_loss: 0.024), lr: 0.004999730 validation, acc: 0.679, loss: 2.190 \n",
            "epoch: 109, acc: 0.698, loss: 2.463 (data_loss: 2.439, reg_loss: 0.024), lr: 0.004999728 validation, acc: 0.755, loss: 1.882 \n",
            "epoch: 110, acc: 0.723, loss: 2.245 (data_loss: 2.221, reg_loss: 0.024), lr: 0.004999725 validation, acc: 0.762, loss: 1.785 \n",
            "epoch: 111, acc: 0.779, loss: 1.933 (data_loss: 1.910, reg_loss: 0.024), lr: 0.004999723 validation, acc: 0.772, loss: 1.672 \n",
            "epoch: 112, acc: 0.789, loss: 1.888 (data_loss: 1.864, reg_loss: 0.024), lr: 0.004999720 validation, acc: 0.762, loss: 1.645 \n",
            "epoch: 113, acc: 0.781, loss: 1.787 (data_loss: 1.763, reg_loss: 0.024), lr: 0.004999718 validation, acc: 0.774, loss: 1.439 \n",
            "epoch: 114, acc: 0.877, loss: 1.404 (data_loss: 1.380, reg_loss: 0.024), lr: 0.004999715 validation, acc: 0.884, loss: 1.230 \n",
            "epoch: 115, acc: 0.883, loss: 1.331 (data_loss: 1.307, reg_loss: 0.024), lr: 0.004999713 validation, acc: 0.884, loss: 1.214 \n",
            "epoch: 116, acc: 0.829, loss: 1.410 (data_loss: 1.385, reg_loss: 0.024), lr: 0.004999710 validation, acc: 0.864, loss: 1.250 \n",
            "epoch: 117, acc: 0.858, loss: 1.491 (data_loss: 1.467, reg_loss: 0.024), lr: 0.004999708 validation, acc: 0.869, loss: 1.352 \n",
            "epoch: 118, acc: 0.776, loss: 1.630 (data_loss: 1.606, reg_loss: 0.024), lr: 0.004999705 validation, acc: 0.868, loss: 1.377 \n",
            "epoch: 119, acc: 0.793, loss: 1.876 (data_loss: 1.852, reg_loss: 0.024), lr: 0.004999703 validation, acc: 0.790, loss: 1.584 \n",
            "epoch: 120, acc: 0.793, loss: 1.690 (data_loss: 1.666, reg_loss: 0.024), lr: 0.004999700 validation, acc: 0.805, loss: 1.386 \n",
            "epoch: 121, acc: 0.824, loss: 1.438 (data_loss: 1.414, reg_loss: 0.024), lr: 0.004999698 validation, acc: 0.850, loss: 1.281 \n",
            "epoch: 122, acc: 0.667, loss: 2.450 (data_loss: 2.426, reg_loss: 0.025), lr: 0.004999695 validation, acc: 0.718, loss: 1.971 \n",
            "epoch: 123, acc: 0.668, loss: 2.369 (data_loss: 2.344, reg_loss: 0.025), lr: 0.004999693 validation, acc: 0.672, loss: 2.003 \n",
            "epoch: 124, acc: 0.697, loss: 2.692 (data_loss: 2.667, reg_loss: 0.025), lr: 0.004999690 validation, acc: 0.681, loss: 2.087 \n",
            "epoch: 125, acc: 0.704, loss: 2.299 (data_loss: 2.274, reg_loss: 0.025), lr: 0.004999688 validation, acc: 0.789, loss: 1.678 \n",
            "epoch: 126, acc: 0.598, loss: 2.450 (data_loss: 2.424, reg_loss: 0.025), lr: 0.004999685 validation, acc: 0.610, loss: 2.161 \n",
            "epoch: 127, acc: 0.603, loss: 2.519 (data_loss: 2.493, reg_loss: 0.026), lr: 0.004999683 validation, acc: 0.683, loss: 1.901 \n",
            "epoch: 128, acc: 0.689, loss: 2.975 (data_loss: 2.949, reg_loss: 0.026), lr: 0.004999680 validation, acc: 0.689, loss: 2.317 \n",
            "epoch: 129, acc: 0.597, loss: 3.176 (data_loss: 3.150, reg_loss: 0.026), lr: 0.004999678 validation, acc: 0.561, loss: 2.571 \n",
            "epoch: 130, acc: 0.578, loss: 3.168 (data_loss: 3.141, reg_loss: 0.027), lr: 0.004999675 validation, acc: 0.561, loss: 2.608 \n",
            "epoch: 131, acc: 0.574, loss: 3.109 (data_loss: 3.082, reg_loss: 0.027), lr: 0.004999673 validation, acc: 0.590, loss: 2.527 \n",
            "epoch: 132, acc: 0.602, loss: 2.871 (data_loss: 2.844, reg_loss: 0.027), lr: 0.004999670 validation, acc: 0.593, loss: 2.359 \n",
            "epoch: 133, acc: 0.599, loss: 2.922 (data_loss: 2.895, reg_loss: 0.027), lr: 0.004999668 validation, acc: 0.592, loss: 2.300 \n",
            "epoch: 134, acc: 0.591, loss: 2.774 (data_loss: 2.747, reg_loss: 0.027), lr: 0.004999665 validation, acc: 0.559, loss: 2.434 \n",
            "epoch: 135, acc: 0.564, loss: 2.677 (data_loss: 2.650, reg_loss: 0.027), lr: 0.004999663 validation, acc: 0.678, loss: 2.228 \n",
            "epoch: 136, acc: 0.617, loss: 2.882 (data_loss: 2.855, reg_loss: 0.027), lr: 0.004999660 validation, acc: 0.660, loss: 2.481 \n",
            "epoch: 137, acc: 0.568, loss: 3.260 (data_loss: 3.233, reg_loss: 0.027), lr: 0.004999658 validation, acc: 0.583, loss: 2.655 \n",
            "epoch: 138, acc: 0.521, loss: 3.188 (data_loss: 3.161, reg_loss: 0.027), lr: 0.004999655 validation, acc: 0.569, loss: 2.503 \n",
            "epoch: 139, acc: 0.580, loss: 3.091 (data_loss: 3.064, reg_loss: 0.027), lr: 0.004999653 validation, acc: 0.710, loss: 2.452 \n",
            "epoch: 140, acc: 0.616, loss: 2.922 (data_loss: 2.895, reg_loss: 0.027), lr: 0.004999650 validation, acc: 0.594, loss: 2.445 \n",
            "epoch: 141, acc: 0.607, loss: 2.969 (data_loss: 2.943, reg_loss: 0.026), lr: 0.004999648 validation, acc: 0.679, loss: 2.391 \n",
            "epoch: 142, acc: 0.680, loss: 2.333 (data_loss: 2.307, reg_loss: 0.026), lr: 0.004999645 validation, acc: 0.706, loss: 1.901 \n",
            "epoch: 143, acc: 0.702, loss: 2.224 (data_loss: 2.198, reg_loss: 0.026), lr: 0.004999643 validation, acc: 0.739, loss: 1.953 \n",
            "epoch: 144, acc: 0.702, loss: 2.182 (data_loss: 2.156, reg_loss: 0.026), lr: 0.004999640 validation, acc: 0.754, loss: 1.830 \n",
            "epoch: 145, acc: 0.761, loss: 1.987 (data_loss: 1.961, reg_loss: 0.026), lr: 0.004999638 validation, acc: 0.759, loss: 1.727 \n",
            "epoch: 146, acc: 0.622, loss: 2.178 (data_loss: 2.152, reg_loss: 0.026), lr: 0.004999635 validation, acc: 0.657, loss: 1.869 \n",
            "epoch: 147, acc: 0.663, loss: 2.047 (data_loss: 2.021, reg_loss: 0.026), lr: 0.004999633 validation, acc: 0.655, loss: 1.838 \n",
            "epoch: 148, acc: 0.660, loss: 2.057 (data_loss: 2.031, reg_loss: 0.026), lr: 0.004999630 validation, acc: 0.713, loss: 1.654 \n",
            "epoch: 149, acc: 0.711, loss: 1.791 (data_loss: 1.765, reg_loss: 0.026), lr: 0.004999628 validation, acc: 0.786, loss: 1.517 \n",
            "epoch: 150, acc: 0.788, loss: 1.679 (data_loss: 1.653, reg_loss: 0.026), lr: 0.004999625 validation, acc: 0.775, loss: 1.478 \n",
            "epoch: 151, acc: 0.671, loss: 2.004 (data_loss: 1.978, reg_loss: 0.026), lr: 0.004999623 validation, acc: 0.740, loss: 1.556 \n",
            "epoch: 152, acc: 0.719, loss: 1.839 (data_loss: 1.813, reg_loss: 0.026), lr: 0.004999620 validation, acc: 0.797, loss: 1.544 \n",
            "epoch: 153, acc: 0.794, loss: 1.691 (data_loss: 1.666, reg_loss: 0.026), lr: 0.004999618 validation, acc: 0.735, loss: 1.760 \n",
            "epoch: 154, acc: 0.734, loss: 2.217 (data_loss: 2.191, reg_loss: 0.026), lr: 0.004999615 validation, acc: 0.759, loss: 2.024 \n",
            "epoch: 155, acc: 0.755, loss: 2.129 (data_loss: 2.103, reg_loss: 0.026), lr: 0.004999613 validation, acc: 0.770, loss: 1.924 \n",
            "epoch: 156, acc: 0.779, loss: 1.996 (data_loss: 1.970, reg_loss: 0.026), lr: 0.004999610 validation, acc: 0.769, loss: 1.845 \n",
            "epoch: 157, acc: 0.774, loss: 1.932 (data_loss: 1.906, reg_loss: 0.026), lr: 0.004999608 validation, acc: 0.788, loss: 1.745 \n",
            "epoch: 158, acc: 0.799, loss: 1.826 (data_loss: 1.800, reg_loss: 0.026), lr: 0.004999605 validation, acc: 0.790, loss: 1.753 \n",
            "epoch: 159, acc: 0.803, loss: 1.782 (data_loss: 1.756, reg_loss: 0.026), lr: 0.004999603 validation, acc: 0.845, loss: 1.787 \n",
            "epoch: 160, acc: 0.848, loss: 1.742 (data_loss: 1.716, reg_loss: 0.026), lr: 0.004999600 validation, acc: 0.870, loss: 1.846 \n",
            "epoch: 161, acc: 0.888, loss: 1.697 (data_loss: 1.671, reg_loss: 0.026), lr: 0.004999598 validation, acc: 0.881, loss: 1.892 \n",
            "epoch: 162, acc: 0.897, loss: 1.668 (data_loss: 1.641, reg_loss: 0.026), lr: 0.004999595 validation, acc: 0.884, loss: 1.883 \n",
            "epoch: 163, acc: 0.900, loss: 1.643 (data_loss: 1.616, reg_loss: 0.026), lr: 0.004999593 validation, acc: 0.884, loss: 1.893 \n",
            "epoch: 164, acc: 0.900, loss: 1.625 (data_loss: 1.599, reg_loss: 0.026), lr: 0.004999590 validation, acc: 0.883, loss: 1.882 \n",
            "epoch: 165, acc: 0.898, loss: 1.616 (data_loss: 1.590, reg_loss: 0.026), lr: 0.004999588 validation, acc: 0.887, loss: 1.857 \n",
            "epoch: 166, acc: 0.882, loss: 1.637 (data_loss: 1.611, reg_loss: 0.026), lr: 0.004999585 validation, acc: 0.885, loss: 1.747 \n",
            "epoch: 167, acc: 0.901, loss: 1.594 (data_loss: 1.569, reg_loss: 0.026), lr: 0.004999583 validation, acc: 0.883, loss: 1.767 \n",
            "epoch: 168, acc: 0.897, loss: 1.623 (data_loss: 1.597, reg_loss: 0.025), lr: 0.004999580 validation, acc: 0.873, loss: 1.783 \n",
            "epoch: 169, acc: 0.890, loss: 1.650 (data_loss: 1.625, reg_loss: 0.025), lr: 0.004999578 validation, acc: 0.881, loss: 1.711 \n",
            "epoch: 170, acc: 0.896, loss: 1.623 (data_loss: 1.598, reg_loss: 0.025), lr: 0.004999575 validation, acc: 0.882, loss: 1.693 \n",
            "epoch: 171, acc: 0.900, loss: 1.603 (data_loss: 1.579, reg_loss: 0.024), lr: 0.004999573 validation, acc: 0.882, loss: 1.774 \n",
            "epoch: 172, acc: 0.899, loss: 1.613 (data_loss: 1.589, reg_loss: 0.024), lr: 0.004999570 validation, acc: 0.882, loss: 1.831 \n",
            "epoch: 173, acc: 0.899, loss: 1.601 (data_loss: 1.577, reg_loss: 0.024), lr: 0.004999568 validation, acc: 0.880, loss: 1.868 \n",
            "epoch: 174, acc: 0.898, loss: 1.599 (data_loss: 1.576, reg_loss: 0.023), lr: 0.004999565 validation, acc: 0.882, loss: 1.860 \n",
            "epoch: 175, acc: 0.900, loss: 1.593 (data_loss: 1.569, reg_loss: 0.023), lr: 0.004999563 validation, acc: 0.884, loss: 1.841 \n",
            "epoch: 176, acc: 0.895, loss: 1.609 (data_loss: 1.587, reg_loss: 0.023), lr: 0.004999560 validation, acc: 0.879, loss: 1.828 \n",
            "epoch: 177, acc: 0.846, loss: 1.755 (data_loss: 1.733, reg_loss: 0.023), lr: 0.004999558 validation, acc: 0.876, loss: 1.867 \n",
            "epoch: 178, acc: 0.889, loss: 1.645 (data_loss: 1.623, reg_loss: 0.022), lr: 0.004999555 validation, acc: 0.819, loss: 2.000 \n",
            "epoch: 179, acc: 0.838, loss: 1.739 (data_loss: 1.717, reg_loss: 0.022), lr: 0.004999553 validation, acc: 0.861, loss: 1.824 \n",
            "epoch: 180, acc: 0.719, loss: 2.337 (data_loss: 2.315, reg_loss: 0.022), lr: 0.004999550 validation, acc: 0.723, loss: 2.172 \n",
            "epoch: 181, acc: 0.698, loss: 2.349 (data_loss: 2.328, reg_loss: 0.022), lr: 0.004999548 validation, acc: 0.798, loss: 1.891 \n",
            "epoch: 182, acc: 0.702, loss: 1.597 (data_loss: 1.575, reg_loss: 0.021), lr: 0.004999545 validation, acc: 0.861, loss: 1.169 \n",
            "epoch: 183, acc: 0.792, loss: 1.424 (data_loss: 1.403, reg_loss: 0.021), lr: 0.004999543 validation, acc: 0.797, loss: 1.386 \n",
            "epoch: 184, acc: 0.762, loss: 1.521 (data_loss: 1.500, reg_loss: 0.021), lr: 0.004999540 validation, acc: 0.841, loss: 1.410 \n",
            "epoch: 185, acc: 0.729, loss: 1.390 (data_loss: 1.369, reg_loss: 0.021), lr: 0.004999538 validation, acc: 0.823, loss: 1.129 \n",
            "epoch: 186, acc: 0.751, loss: 1.240 (data_loss: 1.218, reg_loss: 0.022), lr: 0.004999535 validation, acc: 0.773, loss: 1.017 \n",
            "epoch: 187, acc: 0.767, loss: 1.057 (data_loss: 1.035, reg_loss: 0.022), lr: 0.004999533 validation, acc: 0.759, loss: 0.957 \n",
            "epoch: 188, acc: 0.697, loss: 1.332 (data_loss: 1.310, reg_loss: 0.022), lr: 0.004999530 validation, acc: 0.706, loss: 1.055 \n",
            "epoch: 189, acc: 0.712, loss: 1.128 (data_loss: 1.106, reg_loss: 0.022), lr: 0.004999528 validation, acc: 0.756, loss: 0.878 \n",
            "epoch: 190, acc: 0.745, loss: 1.243 (data_loss: 1.221, reg_loss: 0.022), lr: 0.004999525 validation, acc: 0.772, loss: 1.047 \n",
            "epoch: 191, acc: 0.775, loss: 1.143 (data_loss: 1.121, reg_loss: 0.023), lr: 0.004999523 validation, acc: 0.780, loss: 0.956 \n",
            "epoch: 192, acc: 0.790, loss: 1.034 (data_loss: 1.011, reg_loss: 0.023), lr: 0.004999520 validation, acc: 0.782, loss: 0.932 \n",
            "epoch: 193, acc: 0.792, loss: 0.595 (data_loss: 0.572, reg_loss: 0.023), lr: 0.004999518 validation, acc: 0.859, loss: 0.472 \n",
            "epoch: 194, acc: 0.721, loss: 0.921 (data_loss: 0.898, reg_loss: 0.023), lr: 0.004999515 validation, acc: 0.757, loss: 0.808 \n",
            "epoch: 195, acc: 0.722, loss: 1.008 (data_loss: 0.984, reg_loss: 0.024), lr: 0.004999513 validation, acc: 0.684, loss: 0.900 \n",
            "epoch: 196, acc: 0.680, loss: 0.976 (data_loss: 0.952, reg_loss: 0.024), lr: 0.004999510 validation, acc: 0.692, loss: 0.848 \n",
            "epoch: 197, acc: 0.707, loss: 0.905 (data_loss: 0.880, reg_loss: 0.024), lr: 0.004999508 validation, acc: 0.753, loss: 0.764 \n",
            "epoch: 198, acc: 0.756, loss: 0.806 (data_loss: 0.781, reg_loss: 0.024), lr: 0.004999505 validation, acc: 0.857, loss: 0.652 \n",
            "epoch: 199, acc: 0.746, loss: 0.985 (data_loss: 0.961, reg_loss: 0.024), lr: 0.004999503 validation, acc: 0.792, loss: 0.826 \n",
            "epoch: 200, acc: 0.685, loss: 1.098 (data_loss: 1.073, reg_loss: 0.024), lr: 0.004999500 validation, acc: 0.766, loss: 0.837 \n",
            "epoch: 201, acc: 0.652, loss: 1.470 (data_loss: 1.445, reg_loss: 0.025), lr: 0.004999498 validation, acc: 0.664, loss: 1.192 \n",
            "epoch: 202, acc: 0.605, loss: 1.460 (data_loss: 1.435, reg_loss: 0.025), lr: 0.004999495 validation, acc: 0.634, loss: 1.039 \n",
            "epoch: 203, acc: 0.627, loss: 1.094 (data_loss: 1.069, reg_loss: 0.025), lr: 0.004999493 validation, acc: 0.783, loss: 0.744 \n",
            "epoch: 204, acc: 0.683, loss: 0.873 (data_loss: 0.848, reg_loss: 0.025), lr: 0.004999490 validation, acc: 0.818, loss: 0.650 \n",
            "epoch: 205, acc: 0.792, loss: 0.881 (data_loss: 0.856, reg_loss: 0.025), lr: 0.004999488 validation, acc: 0.873, loss: 0.625 \n",
            "epoch: 206, acc: 0.867, loss: 0.668 (data_loss: 0.643, reg_loss: 0.025), lr: 0.004999485 validation, acc: 0.888, loss: 0.496 \n",
            "epoch: 207, acc: 0.864, loss: 0.508 (data_loss: 0.483, reg_loss: 0.025), lr: 0.004999483 validation, acc: 0.906, loss: 0.423 \n",
            "epoch: 208, acc: 0.904, loss: 0.372 (data_loss: 0.347, reg_loss: 0.025), lr: 0.004999480 validation, acc: 0.972, loss: 0.307 \n",
            "epoch: 209, acc: 0.976, loss: 0.264 (data_loss: 0.239, reg_loss: 0.026), lr: 0.004999478 validation, acc: 0.973, loss: 0.258 \n",
            "epoch: 210, acc: 0.823, loss: 0.520 (data_loss: 0.494, reg_loss: 0.026), lr: 0.004999475 validation, acc: 0.822, loss: 0.451 \n",
            "epoch: 211, acc: 0.812, loss: 0.467 (data_loss: 0.441, reg_loss: 0.026), lr: 0.004999473 validation, acc: 0.892, loss: 0.366 \n",
            "epoch: 212, acc: 0.895, loss: 0.370 (data_loss: 0.344, reg_loss: 0.026), lr: 0.004999470 validation, acc: 0.861, loss: 0.403 \n",
            "epoch: 213, acc: 0.870, loss: 0.405 (data_loss: 0.379, reg_loss: 0.026), lr: 0.004999468 validation, acc: 0.876, loss: 0.338 \n",
            "epoch: 214, acc: 0.800, loss: 0.491 (data_loss: 0.465, reg_loss: 0.026), lr: 0.004999465 validation, acc: 0.880, loss: 0.312 \n",
            "epoch: 215, acc: 0.876, loss: 0.315 (data_loss: 0.288, reg_loss: 0.026), lr: 0.004999463 validation, acc: 0.959, loss: 0.186 \n",
            "epoch: 216, acc: 0.914, loss: 0.265 (data_loss: 0.238, reg_loss: 0.026), lr: 0.004999460 validation, acc: 0.966, loss: 0.175 \n",
            "epoch: 217, acc: 0.866, loss: 0.294 (data_loss: 0.268, reg_loss: 0.027), lr: 0.004999458 validation, acc: 0.946, loss: 0.214 \n",
            "epoch: 218, acc: 0.851, loss: 0.655 (data_loss: 0.628, reg_loss: 0.027), lr: 0.004999455 validation, acc: 0.877, loss: 0.607 \n",
            "epoch: 219, acc: 0.856, loss: 0.753 (data_loss: 0.726, reg_loss: 0.027), lr: 0.004999453 validation, acc: 0.881, loss: 0.826 \n",
            "epoch: 220, acc: 0.859, loss: 1.040 (data_loss: 1.013, reg_loss: 0.027), lr: 0.004999450 validation, acc: 0.863, loss: 0.979 \n",
            "epoch: 221, acc: 0.824, loss: 1.280 (data_loss: 1.253, reg_loss: 0.027), lr: 0.004999448 validation, acc: 0.882, loss: 0.663 \n",
            "epoch: 222, acc: 0.880, loss: 0.833 (data_loss: 0.806, reg_loss: 0.027), lr: 0.004999445 validation, acc: 0.868, loss: 0.610 \n",
            "epoch: 223, acc: 0.874, loss: 0.758 (data_loss: 0.731, reg_loss: 0.027), lr: 0.004999443 validation, acc: 0.885, loss: 0.557 \n",
            "epoch: 224, acc: 0.886, loss: 0.703 (data_loss: 0.676, reg_loss: 0.027), lr: 0.004999440 validation, acc: 0.891, loss: 0.620 \n",
            "epoch: 225, acc: 0.875, loss: 0.810 (data_loss: 0.784, reg_loss: 0.027), lr: 0.004999438 validation, acc: 0.880, loss: 0.695 \n",
            "epoch: 226, acc: 0.872, loss: 0.889 (data_loss: 0.862, reg_loss: 0.027), lr: 0.004999435 validation, acc: 0.897, loss: 0.564 \n",
            "epoch: 227, acc: 0.890, loss: 0.732 (data_loss: 0.705, reg_loss: 0.026), lr: 0.004999433 validation, acc: 0.893, loss: 0.522 \n",
            "epoch: 228, acc: 0.889, loss: 0.667 (data_loss: 0.641, reg_loss: 0.026), lr: 0.004999430 validation, acc: 0.887, loss: 0.560 \n",
            "epoch: 229, acc: 0.864, loss: 0.762 (data_loss: 0.736, reg_loss: 0.026), lr: 0.004999428 validation, acc: 0.885, loss: 0.562 \n",
            "epoch: 230, acc: 0.888, loss: 0.675 (data_loss: 0.650, reg_loss: 0.025), lr: 0.004999425 validation, acc: 0.893, loss: 0.600 \n",
            "epoch: 231, acc: 0.889, loss: 0.748 (data_loss: 0.723, reg_loss: 0.025), lr: 0.004999423 validation, acc: 0.881, loss: 0.591 \n",
            "epoch: 232, acc: 0.831, loss: 0.832 (data_loss: 0.807, reg_loss: 0.025), lr: 0.004999420 validation, acc: 0.901, loss: 0.549 \n",
            "epoch: 233, acc: 0.892, loss: 0.708 (data_loss: 0.683, reg_loss: 0.025), lr: 0.004999418 validation, acc: 0.901, loss: 0.504 \n",
            "epoch: 234, acc: 0.894, loss: 0.625 (data_loss: 0.601, reg_loss: 0.024), lr: 0.004999415 validation, acc: 0.900, loss: 0.434 \n",
            "epoch: 235, acc: 0.893, loss: 0.536 (data_loss: 0.512, reg_loss: 0.024), lr: 0.004999413 validation, acc: 0.898, loss: 0.395 \n",
            "epoch: 236, acc: 0.891, loss: 0.699 (data_loss: 0.675, reg_loss: 0.024), lr: 0.004999410 validation, acc: 0.901, loss: 0.555 \n",
            "epoch: 237, acc: 0.894, loss: 0.700 (data_loss: 0.677, reg_loss: 0.024), lr: 0.004999408 validation, acc: 0.902, loss: 0.528 \n",
            "epoch: 238, acc: 0.894, loss: 0.674 (data_loss: 0.650, reg_loss: 0.023), lr: 0.004999405 validation, acc: 0.902, loss: 0.481 \n",
            "epoch: 239, acc: 0.893, loss: 0.606 (data_loss: 0.583, reg_loss: 0.023), lr: 0.004999403 validation, acc: 0.902, loss: 0.447 \n",
            "epoch: 240, acc: 0.894, loss: 0.558 (data_loss: 0.535, reg_loss: 0.023), lr: 0.004999400 validation, acc: 0.902, loss: 0.415 \n",
            "epoch: 241, acc: 0.896, loss: 0.511 (data_loss: 0.488, reg_loss: 0.023), lr: 0.004999398 validation, acc: 0.902, loss: 0.388 \n",
            "epoch: 242, acc: 0.869, loss: 0.525 (data_loss: 0.503, reg_loss: 0.022), lr: 0.004999395 validation, acc: 0.901, loss: 0.382 \n",
            "epoch: 243, acc: 0.895, loss: 0.456 (data_loss: 0.434, reg_loss: 0.022), lr: 0.004999393 validation, acc: 0.899, loss: 0.369 \n",
            "epoch: 244, acc: 0.876, loss: 0.488 (data_loss: 0.466, reg_loss: 0.021), lr: 0.004999390 validation, acc: 0.901, loss: 0.339 \n",
            "epoch: 245, acc: 0.895, loss: 0.386 (data_loss: 0.365, reg_loss: 0.021), lr: 0.004999388 validation, acc: 0.902, loss: 0.266 \n",
            "epoch: 246, acc: 0.894, loss: 0.315 (data_loss: 0.294, reg_loss: 0.021), lr: 0.004999385 validation, acc: 0.942, loss: 0.227 \n",
            "epoch: 247, acc: 0.934, loss: 0.233 (data_loss: 0.213, reg_loss: 0.020), lr: 0.004999383 validation, acc: 0.990, loss: 0.194 \n",
            "epoch: 248, acc: 0.990, loss: 0.172 (data_loss: 0.152, reg_loss: 0.020), lr: 0.004999380 validation, acc: 0.988, loss: 0.155 \n",
            "epoch: 249, acc: 0.997, loss: 0.119 (data_loss: 0.099, reg_loss: 0.020), lr: 0.004999378 validation, acc: 0.994, loss: 0.115 \n",
            "epoch: 250, acc: 0.995, loss: 0.095 (data_loss: 0.076, reg_loss: 0.019), lr: 0.004999375 validation, acc: 0.999, loss: 0.086 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR0u0Jm7QCrw"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KNnDUP_U8Xn",
        "outputId": "bcf1644d-5428-411f-bbdc-6d7138277f74"
      },
      "source": [
        "print(np.mean(acc_cache))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7416289840637449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NbXMisqQKqF",
        "outputId": "46fe4c45-eab2-438a-ff08-470860e4a4ea"
      },
      "source": [
        "for milestone in summary:\n",
        "  print(milestone)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model hit 80% validation accuracy in 22 epochs\n",
            "Model hit 85% validation accuracy in 23 epochs\n",
            "Model hit 90% validation accuracy in 24 epochs\n",
            "Model hit 95% validation accuracy in 90 epochs\n",
            "Model hit 97.5% validation accuracy in 91 epochs\n",
            "Max accuracy was 99.9375% at epoch 250.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rVqT3yaXS5k"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smwSXsZVU8Xo",
        "outputId": "c2ee5e17-554b-422b-9f32-d88e7bdc877b"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(y_test)\n",
        "\n",
        "dense1.forward(X_test)\n",
        "\n",
        "activation1.forward(dense1.output)\n",
        "\n",
        "dropout1.infrence(activation1.output,y_test)\n",
        "\n",
        "\n",
        "dense2.forward(dropout1.output)\n",
        "\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "dense3.forward(activation2.output)\n",
        "\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "dense4.forward(activation3.output)\n",
        "\n",
        "activation4.forward(dense4.output)\n",
        "\n",
        "# Calculate the data loss\n",
        "loss = loss_function.calculate(activation4.output, y_test)\n",
        "\n",
        "predictions = activation4.predictions(activation4.output)\n",
        "testaccuracy = accuracy.calculate(predictions, y_test)\n",
        "\n",
        "print(f'Accuracy: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.999, loss: 0.086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k0Ve2M0bPG3"
      },
      "source": [
        "training_diff = []\n",
        "testing_diff = []\n",
        "combined_diff = []"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MByL_RwvlIx3"
      },
      "source": [
        "Individual Training Classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTOnqnDXa0ME",
        "outputId": "2ced3b36-7e8a-4474-ecf9-7132ad28a052"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "for classes, (X_sorted_lists, y_sorted_lists) in enumerate(zip(sorted_x, sorted_y)):\n",
        "  accuracy = Accuracy_Categorical()\n",
        "\n",
        "  y = sorted_y[y_sorted_lists]\n",
        "  X = sorted_x[X_sorted_lists]\n",
        "  accuracy.init(y)\n",
        "\n",
        "  dense1.forward(X)\n",
        "\n",
        "  activation1.forward(dense1.output)\n",
        "  train_train_mean = activation1.output\n",
        "\n",
        "  dropout1.infrence(activation1.output,y)\n",
        "\n",
        "  dense2.forward(dropout1.output)\n",
        "\n",
        "  activation2.forward(dense2.output)\n",
        "\n",
        "  dense3.forward(activation2.output)\n",
        "\n",
        "  activation3.forward(dense3.output)\n",
        "\n",
        "  dense4.forward(activation3.output)\n",
        "\n",
        "  activation4.forward(dense4.output)\n",
        "\n",
        "  # Calculate the data loss\n",
        "  loss = loss_function.calculate(activation4.output, y)\n",
        "\n",
        "  predictions = activation4.predictions(activation4.output)\n",
        "  testaccuracy = accuracy.calculate(predictions, y)\n",
        "  print(f'{number_mnist_labels[classes]} Train Accuracy: {testaccuracy:.3f}, loss: {loss:.3f}')\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train Accuracy: 0.999, loss: 0.037\n",
            "1 Train Accuracy: 1.000, loss: 0.072\n",
            "2 Train Accuracy: 1.000, loss: 0.001\n",
            "3 Train Accuracy: 0.987, loss: 0.278\n",
            "4 Train Accuracy: 1.000, loss: 0.000\n",
            "5 Train Accuracy: 1.000, loss: 0.006\n",
            "6 Train Accuracy: 1.000, loss: 0.003\n",
            "7 Train Accuracy: 0.999, loss: 0.035\n",
            "8 Train Accuracy: 1.000, loss: 0.259\n",
            "9 Train Accuracy: 0.995, loss: 0.198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scjb7Wh_sn6b",
        "outputId": "ed8ebca6-c978-40ed-bd7b-1556d213fb84"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "for classes, (X_sorted_lists, y_sorted_lists) in enumerate(zip(sorted_x_test, sorted_y_test)):\n",
        "  accuracy.init(y_sorted_lists)\n",
        "  #print(sorted_y[y_sorted_lists].shape)\n",
        "  #print(sorted_x[X_sorted_lists].shape)\n",
        "  dense1.forward(sorted_x_test[X_sorted_lists])\n",
        "\n",
        "  activation1.forward(dense1.output)\n",
        "\n",
        "  testmean = np.mean(activation1.output, axis=0)\n",
        "  testing_diff.append(testmean)\n",
        "  dropout1.infrence(activation1.output,sorted_y_test[y_sorted_lists])\n",
        "\n",
        "  dense2.forward(dropout1.output)\n",
        "\n",
        "  activation2.forward(dense2.output)\n",
        "\n",
        "  dense3.forward(activation2.output)\n",
        "\n",
        "  activation3.forward(dense3.output)\n",
        "\n",
        "  dense4.forward(activation3.output)\n",
        "\n",
        "  activation4.forward(dense4.output)\n",
        "  # Calculate the data loss\n",
        "  loss = loss_function.calculate(activation4.output, sorted_y_test[y_sorted_lists])\n",
        "\n",
        "  predictions = activation4.predictions(activation4.output)\n",
        "  testaccuracy = accuracy.calculate(predictions, sorted_y_test[y_sorted_lists])\n",
        "\n",
        "  print(f'{number_mnist_labels[classes]} Test Accuracy: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test Accuracy: 1.000, loss: 0.037\n",
            "1 Test Accuracy: 1.000, loss: 0.068\n",
            "2 Test Accuracy: 1.000, loss: 0.001\n",
            "3 Test Accuracy: 1.000, loss: 0.293\n",
            "4 Test Accuracy: 1.000, loss: 0.000\n",
            "5 Test Accuracy: 1.000, loss: 0.005\n",
            "6 Test Accuracy: 1.000, loss: 0.003\n",
            "7 Test Accuracy: 1.000, loss: 0.027\n",
            "8 Test Accuracy: 1.000, loss: 0.242\n",
            "9 Test Accuracy: 0.994, loss: 0.187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2u-O8oNZ0qA"
      },
      "source": [
        "# Full mnist test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbD4KrLMnTcR"
      },
      "source": [
        "Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMfBGUHeZ4L5",
        "outputId": "dda2e68b-3174-4796-8ba8-2e6eb2bebfdf"
      },
      "source": [
        "(input, label), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Label index to label name relation\n",
        "number_mnist_labels = {\n",
        "    0: '0',\n",
        "    1: '1',\n",
        "    2: '2',\n",
        "    3: '3',\n",
        "    4: '4',\n",
        "    5: '5',\n",
        "    6: '6',\n",
        "    7: '7',\n",
        "    8: '8',\n",
        "    9: '9'\n",
        "}\n",
        "\n",
        "# Shuffle the training dataset\n",
        "keys = np.array(range(input.shape[0]))\n",
        "np.random.shuffle(keys)\n",
        "input = input[keys]\n",
        "label = label[keys]\n",
        "\n",
        "\n",
        "# Scale and reshape samples\n",
        "input = (input.reshape(input.shape[0], -1).astype(np.float32) - 127.5) / 127.5\n",
        "X_test = (X_test.reshape(X_test.shape[0], -1).astype(np.float32) -\n",
        "             127.5) / 127.5\n",
        "\n",
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(label)\n",
        "\n",
        "dense1.forward(input)\n",
        "\n",
        "activation1.forward(dense1.output)\n",
        "train_train_mean = activation1.output\n",
        "\n",
        "dropout1.infrence(activation1.output,label)\n",
        "\n",
        "dense2.forward(dropout1.output)\n",
        "\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "dense3.forward(activation2.output)\n",
        "\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "dense4.forward(activation3.output)\n",
        "\n",
        "activation4.forward(dense4.output)\n",
        "\n",
        "# Calculate the data loss\n",
        "loss = loss_function.calculate(activation4.output, label)\n",
        "\n",
        "predictions = activation4.predictions(activation4.output)\n",
        "testaccuracy = accuracy.calculate(predictions, label)\n",
        "\n",
        "print(f'Full Training Accuracy: {testaccuracy:.3f}, loss: {loss:.3f}')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Full Training Accuracy: 0.997, loss: 0.091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aat-uVF6nYu7"
      },
      "source": [
        "Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hyU1tBDna8x",
        "outputId": "624ede43-450d-493e-9609-2708ca2f7cc5"
      },
      "source": [
        "accuracy = Accuracy_Categorical()\n",
        "\n",
        "accuracy.init(y_test)\n",
        "\n",
        "dense1.forward(X_test)\n",
        "\n",
        "activation1.forward(dense1.output)\n",
        "train_train_mean = activation1.output\n",
        "\n",
        "dropout1.infrence(activation1.output,y_test)\n",
        "\n",
        "dense2.forward(dropout1.output)\n",
        "\n",
        "activation2.forward(dense2.output)\n",
        "\n",
        "dense3.forward(activation2.output)\n",
        "\n",
        "activation3.forward(dense3.output)\n",
        "\n",
        "dense4.forward(activation3.output)\n",
        "\n",
        "activation4.forward(dense4.output)\n",
        "\n",
        "# Calculate the data loss\n",
        "loss = loss_function.calculate(activation4.output, y_test)\n",
        "\n",
        "predictions = activation4.predictions(activation4.output)\n",
        "testaccuracy = accuracy.calculate(predictions, y_test)\n",
        "\n",
        "print(f'Full Testing Accuracy: {testaccuracy:.5f}, loss: {loss:.3f}')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Full Testing Accuracy: 0.99938, loss: 0.086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0deRpPodLm04"
      },
      "source": [
        "Change idex to get confidence of different samples of testing data. Index values 0-1600 were refrenced in training. Anything past was never seen during training. Lowest confidence is at index 7821 when trained with 250 epochs and numpy seed set to 22."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "DdktRypGH2Gw",
        "outputId": "76677993-b8af-4a5d-839b-127a51b1ba6f"
      },
      "source": [
        "index = 6796\n",
        "\n",
        "print(f'{(activation4.output[index][np.where(activation4.output[index] == np.amax(activation4.output[index]))][0]*100):.3f}% Confident True is {number_mnist_labels[np.where(activation4.output[index] == np.amax(activation4.output[index]))[0][0]]}. True is actually {number_mnist_labels[y_test[index]]}')\n",
        "\n",
        "X_test.resize(X_test.shape[0],28,28)\n",
        "image = X_test[index]\n",
        "fig = plt.figure\n",
        "plt.title(f'{number_mnist_labels[y_test[index]]}')\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.775% Confident True is 2. True is actually 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRXGM4hyXmr7"
      },
      "source": [
        "Plotting Graphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "h5c5xUTNXk2v",
        "outputId": "3996128c-b76a-406c-9686-0af8eeba96f4"
      },
      "source": [
        "plt.plot(epoch_cache, val_loss_cache, label='Validation Loss')\n",
        "plt.plot(epoch_cache, loss_cache, label='Training Loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_cache, val_acc_cache, label='Validation Accuracy')\n",
        "plt.plot(epoch_cache, acc_cache, label='Training Accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epoch_cache, lr_cache, label='LR')\n",
        "plt.title('Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}